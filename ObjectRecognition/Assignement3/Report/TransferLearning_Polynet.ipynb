{
  "cells": [
    {
      "metadata": {
        "_uuid": "62d4c1dbaa272ae53666c3f920ac525555117ba8"
      },
      "cell_type": "markdown",
      "source": "# This notebook aims at applying transfer learning\n\nhttps://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5b1c3bae9674d5f29f9a871f02996a23d9d88325",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "from __future__ import print_function, division\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport numpy as np\nimport torchvision\nfrom torchvision import datasets, models, transforms\nimport matplotlib.pyplot as plt\nfrom shutil import copyfile\ncopyfile(\"../input/modelpretrained/Poly_Net.py\", \"../working/polynet.py\")\nimport time\nimport os\nimport copy\n\nplt.ion()   # interactive mode\n\n\ndef create_download_link(title=\"Download CSV file\", filename=\"experiment/kaggle.csv\"):\n    df = pd.read_csv(filename)\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\n\n\ndef train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train_images', 'val_images']:\n            if phase == 'train_images':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train_images'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train_images':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val_images' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef evaluate_model(model, criterion, optimizer, scheduler, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train_images', 'val_images']:\n            if phase == 'train_images':\n                scheduler.step()\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                # zero the parameter gradients\n                optimizer.zero_grad()\n\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train_images'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train_images':\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val_images' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model\n\ndef visualize_model(model, num_images=6):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure()\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val_images']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n\n            for j in range(inputs.size()[0]):\n                images_so_far += 1\n                ax = plt.subplot(num_images//2, 2, images_so_far)\n                ax.axis('off')\n                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)\n        \n\ndef visualize_errors(model, num_images=6, per_col=3):\n    was_training = model.training\n    model.eval()\n    images_so_far = 0\n    fig = plt.figure(figsize=(20,20))\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(dataloaders['val_images']):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            \n            for j in range(inputs.size()[0]):\n                if preds[j] == labels[j]:\n                    continue\n                images_so_far += 1\n                ax = plt.subplot(num_images//per_col, per_col, images_so_far)\n                ax.axis('off')\n                ax.set_title(f\"Pred: {preds[j]:d}, GT: {labels[j]:d}\")\n                imshow(inputs.cpu().data[j])\n\n                if images_so_far == num_images:\n                    model.train(mode=was_training)\n                    return\n        model.train(mode=was_training)\n\n        \nclass ImageFolderWithPaths(datasets.ImageFolder):\n    \"\"\"Custom dataset that includes image file paths. Extends\n    torchvision.datasets.ImageFolder\n    https://gist.github.com/andrewjong/6b02ff237533b3b2c554701fb53d5c4d\n    \"\"\"\n\n    def __getitem__(self, index):\n        original_tuple = super(ImageFolderWithPaths, self).__getitem__(index)\n        path = self.imgs[index][0]\n        tuple_with_path = (original_tuple + (path,))\n        return tuple_with_path\n\n\ndef evaluate_model(model, test_dir, outfile=\"experiment/results.csv\"):\n    model.eval()\n    output_file = open(outfile, \"w\")\n    output_file.write(\"Id,Category\\n\")\n    for inputs, _, paths in testloader:    \n            inputs = inputs.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            for j in range(inputs.size()[0]):\n                output_file.write(\"%s,%d\\n\" % (os.path.splitext(os.path.basename(paths[j]))[0], preds[j]))\n    output_file.close()\n    print(f\"Succesfully wrote {outfile}, you can upload this file to the kaggle competition website\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5820981881bd7f8e62693893d343ba394fe135b2"
      },
      "cell_type": "markdown",
      "source": "# Loading data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a7cc282aadde3bfb88a402e4e7ef6611cafd063"
      },
      "cell_type": "code",
      "source": "# Data augmentation and normalization for training\n# Just normalization for validation\ndata_transforms = {\n    'train_images': transforms.Compose([\n        transforms.RandomResizedCrop(331),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'val_images': transforms.Compose([\n        transforms.Resize(335),\n        transforms.CenterCrop(331),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'test_images': transforms.Compose([\n        transforms.Resize(335),\n        transforms.CenterCrop(331),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}\n\n\n\n\ndata_dir = '../input/bird_dataset/bird_dataset/'\nexperiment = 'experiment/'\ntraining_path = os.path.join(data_dir, 'train_images')\nbird_classes = os.listdir(training_path)\nsample_class = np.random.choice(bird_classes)\n\n# parameters\nn_classes = len(bird_classes)\nseed = 1\nlog_interval = 10\n\n# Create experiment folder\nif not os.path.isdir(experiment):\n    os.makedirs(experiment)\n    \nimage_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n                                          data_transforms[x])\n                  for x in ['train_images', 'val_images', 'test_images']}\ndataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n                                             shuffle=True, num_workers=4)\n              for x in ['train_images', 'val_images', 'test_images']}\ndataset_sizes = {x: len(image_datasets[x]) for x in ['train_images', 'val_images', 'test_images']}\nclass_names = image_datasets['train_images'].classes\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7f0a98cf5f226a579d2dc479e5f00deb5f57ebda"
      },
      "cell_type": "markdown",
      "source": "# Visualize a few images"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6786a98f162aad3a4883c7cf5bf24b1ebadb6fa9"
      },
      "cell_type": "code",
      "source": "def imshow(inp, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  # pause a bit so that plots are updated\n\n\n# Get a batch of training data\ninputs, classes = next(iter(dataloaders['train_images']))\n\n# Make a grid from batch\nout = torchvision.utils.make_grid(inputs)\n\nimshow(out, title=[class_names[x] for x in classes])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4821dd4d56ac9bbd5da94664c1c1cbf45d19bf8d"
      },
      "cell_type": "markdown",
      "source": "# Finetuning the neural network"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bcad2a2cdc8095acc7c3cbb609ee2a24bf765dc2"
      },
      "cell_type": "code",
      "source": "model = polynet(num_classes=1000, pretrained='imagenet')\nfor param in model.parameters():\n    param.requires_grad = False\nnum_ftrs = model_ft.fc.in_features\nmodel_ft.fc = nn.Linear(num_ftrs, n_classes)\n\nmodel_ft = model_ft.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that all parameters are being optimized\noptimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": false,
        "_uuid": "c79394efa2abae57fdf2771dde26eb14c9f3b55f"
      },
      "cell_type": "code",
      "source": "# model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n#                        num_epochs=25)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false,
        "_uuid": "d3efd074ee2b0f2824dcbf4dd44d2793e9137ae7"
      },
      "cell_type": "code",
      "source": "# visualize_model(model_ft)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "5c53b5add342888524a1fe1d9d641d318a2a322d"
      },
      "cell_type": "code",
      "source": "# visualize_errors(model_ft, num_images=20)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "d8382569fa4f03274540cee0f8407fa8fc8695a8"
      },
      "cell_type": "markdown",
      "source": "# ConvNet as Feature extractor"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1ada0472f724854583933051d6e318d48d17bb49"
      },
      "cell_type": "code",
      "source": "model_conv = torchvision.models.resnet18(pretrained=True)\nfor param in model_conv.parameters():\n    param.requires_grad = False\n\n# Parameters of newly constructed modules have requires_grad=True by default\nnum_ftrs = model_conv.fc.in_features\nmodel_conv.fc = nn.Linear(num_ftrs, n_classes*10)\n\n\nmodel_conv = model_conv.to(device)\n\ncriterion = nn.CrossEntropyLoss()\n\n# Observe that only parameters of final layer are being optimized as\n# opoosed to before.\n# optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\noptimizer_conv = optim.RMSProp(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n\n# Decay LR by a factor of 0.1 every 7 epochs\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "72fe0810c1da8ca3c972f9f9bf2a308ab5be0dcb"
      },
      "cell_type": "markdown",
      "source": "# Evaluate model"
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "7da70c8ba8cc24f23e722dabe5ff8b4508157dca"
      },
      "cell_type": "code",
      "source": "test_dir = os.path.join(data_dir, 'test_images/mistery_category')\ndataset = ImageFolderWithPaths(os.path.join(data_dir, \"test_images\"), data_transforms['test_images'])\ntestloader = torch.utils.data.DataLoader(dataset)\n\n\n# evaluate_model(model_ft, test_dir)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "86a06df880c0d0847fbd71ef5700f0d639a007ab"
      },
      "cell_type": "code",
      "source": "create_download_link(filename='experiment/results.csv')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}