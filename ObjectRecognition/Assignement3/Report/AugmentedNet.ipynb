{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a51a928ca391ec5973fd65f32aa66069a62fed07"
      },
      "cell_type": "code",
      "source": "print(os.listdir('../input/bird_dataset/bird_dataset/'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2a23bbbdb7fb37e53ca4708d38989c4fb087cf89"
      },
      "cell_type": "code",
      "source": "bird_classes = os.listdir('../input/bird_dataset/bird_dataset/train_images/')\nsample_class = np.random.choice(bird_classes)\ntraining_path = '../input/bird_dataset/bird_dataset/train_images/'\nsample_image = np.random.choice(os.listdir(training_path+sample_class))\npath_sample_image = training_path + sample_class + '/' + sample_image\n\nx = plt.imread(path_sample_image)\n# Visualize shape of image\nprint(x.shape)\nplt.imshow(x);",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e0295f750d7a2f4ea748386db844f0ce8b70771d"
      },
      "cell_type": "markdown",
      "source": "## data.py"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# data.py\nimport zipfile\nimport os\n\nimport torchvision.transforms as transforms\n\n# once the images are loaded, how do we pre-process them before being passed into the network\n# by default, we resize the images to 64 x 64 in size\n# and normalize them to mean = 0 and standard-deviation = 1 based on statistics collected from\n# the training set\ndata_transforms = transforms.Compose([\n    transforms.Resize((64, 64)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "af7fee13dd2ca2fd9856aa518042ac329ee54d87"
      },
      "cell_type": "markdown",
      "source": "## model.py"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8e19bf8ee128ccc30013202f92b5394fd2bc4bdf"
      },
      "cell_type": "code",
      "source": "# model.py\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nnclasses = 20 \n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv3 = nn.Conv2d(20, 20, kernel_size=5)\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, nclasses)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n        x = F.relu(F.max_pool2d(self.conv3(x), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        return self.fc2(x)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14174549b6cd60d23aef2f7fc45af7b1b2db38c5"
      },
      "cell_type": "markdown",
      "source": "## main.py"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "129f8822d82075b34ea18c862ca8dbeee8ce38ce"
      },
      "cell_type": "code",
      "source": "# main.py\nimport argparse\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets\nfrom torch.autograd import Variable",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a0c985427777ce52843eb12b3fe2e0dfe80ac8c9"
      },
      "cell_type": "code",
      "source": "args_data = '../input/bird_dataset/bird_dataset/'\nargs_batch_size = 64\nargs_epochs = 10\nargs_lr = 0.1\nargs_momentum = 0.5\nargs_seed = 1\nargs_log_interval = 10\nargs_experiment = 'experiment'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6ab0feea774a847f93131b58a58b61c44dd34131"
      },
      "cell_type": "code",
      "source": "use_cuda = torch.cuda.is_available()\ntorch.manual_seed(args_seed)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b18e32618e2caa513c6b414dc2fdbe81e6999a3e"
      },
      "cell_type": "code",
      "source": "# Create experiment folder\nif not os.path.isdir(args_experiment):\n    os.makedirs(args_experiment)\n    \nprint('Folder:')\nfor folder_ in os.listdir():\n    print('    /' + folder_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0dd61ae7a284df965c250550fa4a5bec164c648c"
      },
      "cell_type": "code",
      "source": "train_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(args_data + '/train_images',\n                         transform=data_transforms),\n    batch_size=args_batch_size, shuffle=True, num_workers=1)\n\nval_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(args_data + '/val_images',\n                         transform=data_transforms),\n    batch_size=args_batch_size, shuffle=False, num_workers=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ba5f08ddeb6ff06e75d6b85d29ddb4877e896176"
      },
      "cell_type": "code",
      "source": "model = Net()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "445b8cbcc24fec1bc32ccc0f9da48346cc0c3ecd"
      },
      "cell_type": "code",
      "source": "if use_cuda:\n    print('Using GPU')\n    model.cuda()\nelse:\n    print('Using CPU')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc54b69744c7657fa014d168fead27860dab35f6"
      },
      "cell_type": "code",
      "source": "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ea0fc30cc7cdb4417aeaef5df4fee241ab08437"
      },
      "cell_type": "code",
      "source": "def train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args_log_interval == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss.data.item()))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c318b3a6016bbb009eb34ea9982b6321febcd007"
      },
      "cell_type": "code",
      "source": "def validation():\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    for data, target in val_loader:\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        # sum up batch loss\n        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n        validation_loss += criterion(output, target).data.item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    validation_loss /= len(val_loader.dataset)\n    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        validation_loss, correct, len(val_loader.dataset),\n        100. * correct / len(val_loader.dataset)))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "daf79614533e0d2ccc2441e07f77ed02bae3ad8d",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "for epoch in range(1, args_epochs + 1):\n    train(epoch)\n    validation()\n    model_file = args_experiment + '/model_' + str(epoch) + '.pth'\n    torch.save(model.state_dict(), model_file)\n    print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e2241fb3e4eb0339a4f3df9bcd7c422151bcee5e"
      },
      "cell_type": "code",
      "source": "def get_last_model():\n    model_names = os.listdir('./experiment/')\n    model_numbers = [int(name[6:-4]) for name in model_names]\n    return './experiment/model_{}.pth'.format(np.max(model_numbers))\n\nget_last_model()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a9484c0fafea152ce807573bc95759d9242fe6c"
      },
      "cell_type": "markdown",
      "source": "## evaluate.py"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c8cd16424cd35f3c32e7ea8f96dc3f91410bc461"
      },
      "cell_type": "code",
      "source": "import PIL.Image as Image\nimport torch",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbc77f5d473900bb94b1f2f28d2f31a283506ecc"
      },
      "cell_type": "code",
      "source": "args_outfile = 'experiment/kaggle.csv'\nargs_model = get_last_model()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21c8e6c6e03dba0bc89262be4f914b39391af9a4"
      },
      "cell_type": "code",
      "source": "state_dict = torch.load(args_model)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b38d9ad13612955aee45645000515b72a65650d4"
      },
      "cell_type": "code",
      "source": "model = Net()\nmodel.load_state_dict(state_dict)\nmodel.eval()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "859885ad45ea297244bedd0157635fdbbc42aaaf"
      },
      "cell_type": "code",
      "source": "if use_cuda:\n    print('Using GPU')\n    model.cuda()\nelse:\n    print('Using CPU')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ad30da35b3aeaaf69457ff536670a1aa41f02ac"
      },
      "cell_type": "code",
      "source": "test_dir = args_data + '/test_images/mistery_category'",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "751ecf4fd55fd2cfe92bdce220f8dadf1be35a1b"
      },
      "cell_type": "code",
      "source": "def pil_loader(path):\n    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n    with open(path, 'rb') as f:\n        with Image.open(f) as img:\n            return img.convert('RGB')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a3e64c3c3b4be0cc7d024fc75de1f3d56738487a"
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "5f158287ee77576f1feaae8252e2ab43f6665611"
      },
      "cell_type": "code",
      "source": "output_file = open(args_outfile, \"w\")\noutput_file.write(\"Id,Category\\n\")\nfor f in tqdm(os.listdir(test_dir)):\n    if 'jpg' in f:\n        data = data_transforms(pil_loader(test_dir + '/' + f))\n        data = data.view(1, data.size(0), data.size(1), data.size(2))\n        if use_cuda:\n            data = data.cuda()\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1]\n        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa098f746ad105e82f12f0841f56ab52e6cac080"
      },
      "cell_type": "code",
      "source": "output_file.close()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ea3d0b7ab2a57ed172c449f7c57f2faaf301fc84"
      },
      "cell_type": "code",
      "source": "print(\"Succesfully wrote \" + args_outfile + ', you can upload this file to the kaggle competition website')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "814fea3e6ddd324db85bb05c4c2d93b3a4756cfc"
      },
      "cell_type": "code",
      "source": "# Check if output_file is available\n'kaggle.csv' in os.listdir('./experiment/')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}