{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from shutil import copyfile\n",
    "# copyfile(src=\"../input/functions/utils.py\", dst=\"../working/utils.py\")\n",
    "from utils import *\n",
    "import zipfile\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import base64\n",
    "from tqdm import tqdm\n",
    "\n",
    "is_trained=True\n",
    "\n",
    "def create_download_link(title=\"Download CSV file\", filename=\"experiment/kaggle.csv\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "\n",
    "def sample_image():\n",
    "    bird_classes = os.listdir('../input/bird_dataset/bird_dataset/train_images/')\n",
    "    sample_class = np.random.choice(bird_classes)\n",
    "    training_path = '../input/bird_dataset/bird_dataset/train_images/'\n",
    "    sample_image = np.random.choice(os.listdir(training_path+sample_class))\n",
    "    path_sample_image = training_path + sample_class + '/' + sample_image\n",
    "    x = plt.imread(path_sample_image)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def train(epoch, model, train_loader, record_loss=True):\n",
    "    \"\"\"\n",
    "        Train the global defined model.\n",
    "        Warnings:\n",
    "            model: is a global variable here\n",
    "        Input:\n",
    "            epoch: The index number of the epoch (This is NOT the number of epochs)\n",
    "            record_loss: Record the loss evolution for the model\n",
    "    \"\"\"\n",
    "    # loss recording\n",
    "    loss_evolution = []\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args_log_interval == 0:\n",
    "            loss_value = loss.data.item()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss_value))\n",
    "        if record_loss:\n",
    "            loss_evolution.append(loss_value)\n",
    "\n",
    "    if record_loss:\n",
    "        return loss_evolution\n",
    "\n",
    "def get_model(path_experiment, number=-1):\n",
    "    if number < 0:\n",
    "        model_names = os.listdir(path_experiment)\n",
    "        model_numbers = []\n",
    "        for name in model_names:\n",
    "            regex = r'(\\d+)\\.pth'\n",
    "            pattern = re.compile(regex)\n",
    "            match = re.search(pattern, name)\n",
    "            if match is not None:\n",
    "                model_numbers.append(int(match.group(1)))\n",
    "        number = np.max(model_numbers)\n",
    "    return f'./experiment/model_{number}.pth'\n",
    "\n",
    "\n",
    "def validation(model, val_loader):\n",
    "    \"\"\"\n",
    "        Compute validation score\n",
    "        Warnings:\n",
    "            As in train(), the model is a global variable definition\n",
    "        Input:\n",
    "        Output:\n",
    "            validation_loss <float>\n",
    "            accuracy <float>\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "        validation_loss += criterion(output, target).data.item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        accuracy))\n",
    "\n",
    "    return validation_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a23bbbdb7fb37e53ca4708d38989c4fb087cf89"
   },
   "outputs": [],
   "source": [
    "# bird_classes = os.listdir('../input/mva-recvis-2018/bird_dataset/bird_dataset/train_images/')\n",
    "bird_classes = os.listdir('../input/bird_dataset/bird_dataset/train_images/')\n",
    "sample_class = np.random.choice(bird_classes)\n",
    "training_path = '../input/bird_dataset/bird_dataset/train_images/'\n",
    "\n",
    "# parameters\n",
    "n_classes = len(bird_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0295f750d7a2f4ea748386db844f0ce8b70771d"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "from torchvision.models import alexnet\n",
    "model = alexnet(pretrained=False, num_classes=n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14174549b6cd60d23aef2f7fc45af7b1b2db38c5"
   },
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a0c985427777ce52843eb12b3fe2e0dfe80ac8c9"
   },
   "outputs": [],
   "source": [
    "args_data = '../input/bird_dataset/bird_dataset/'\n",
    "args_batch_size = 100\n",
    "args_epochs = 164\n",
    "args_lr = 0.01\n",
    "args_momentum = 0.5\n",
    "\n",
    "args_seed = 1\n",
    "args_log_interval = 10\n",
    "args_experiment = 'experiment'\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "torch.manual_seed(args_seed)\n",
    "\n",
    "# Create experiment folder\n",
    "if not os.path.isdir(args_experiment):\n",
    "    os.makedirs(args_experiment)\n",
    "    \n",
    "print('Folder:')\n",
    "for folder_ in os.listdir():\n",
    "    print('    /' + folder_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0dd61ae7a284df965c250550fa4a5bec164c648c"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(args_data + '/train_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args_batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(args_data + '/val_images',\n",
    "                         transform=data_transforms),\n",
    "    batch_size=args_batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cc54b69744c7657fa014d168fead27860dab35f6"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=args_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "daf79614533e0d2ccc2441e07f77ed02bae3ad8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go through epochs and record loss on training set and accuracy on\n",
    "train_loss_evolution = []\n",
    "valid_loss_evolution = []\n",
    "valid_accuracy_evolution = []\n",
    "\n",
    "if not is_trained:\n",
    "    for epoch in range(1, args_epochs + 1):\n",
    "        loss_evolution = train(epoch, model, train_loader, record_loss=True)\n",
    "        validation_loss, accuracy = validation(model, val_loader)\n",
    "        # Record\n",
    "        train_loss_evolution.append(loss_evolution)\n",
    "        valid_loss_evolution.append(validation_loss)\n",
    "        valid_accuracy_evolution.append(accuracy)\n",
    "\n",
    "        # Store the last 2 models\n",
    "        if epoch > args_epochs-2:\n",
    "            model_file = args_experiment + '/model_' + str(epoch) + '.pth'\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23a4f61dfe172a157f5c70697547bd0d4f5c786d"
   },
   "source": [
    "#### Visualise loss and accuracy evolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e45a462b5ed206f97147a0d1edadea5814baf207"
   },
   "outputs": [],
   "source": [
    "if not is_trained:\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    plt.subplot('311')\n",
    "    plt.title('Evolution of the training loss')\n",
    "    plt.plot(np.mean(np.array(train_loss_evolution), axis=1), alpha=0.4, label='mean')\n",
    "    plt.plot(np.mean(np.array(train_loss_evolution), axis=1) + 3*np.std(np.array(train_loss_evolution), axis=1), 'rs--', alpha=0.4 ,label='std_bound')\n",
    "    plt.plot(np.mean(np.array(train_loss_evolution), axis=1) - 3*np.std(np.array(train_loss_evolution), axis=1), 'rs--', alpha=0.4)\n",
    "    plt.boxplot(np.array(train_loss_evolution).T)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('validation loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot('312')\n",
    "    plt.title('Validation loss evolution')\n",
    "    plt.plot(np.array(valid_loss_evolution), 'xk')\n",
    "    plt.plot(np.array(valid_loss_evolution), 'k--', alpha=0.4)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot('313')\n",
    "    plt.title('Validation accuracy evolution')\n",
    "    plt.plot(np.array(valid_accuracy_evolution), 'xk')\n",
    "    plt.plot(np.array(valid_accuracy_evolution), 'k--', alpha=0.4)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a9484c0fafea152ce807573bc95759d9242fe6c"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bbc77f5d473900bb94b1f2f28d2f31a283506ecc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "args_outfile = os.path.join(args_experiment, 'kaggle.csv')\n",
    "args_model = get_model(args_experiment)\n",
    "print(f\"Loading {args_model}\")\n",
    "\n",
    "state_dict = torch.load(args_model)\n",
    "# model = Net()\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "\n",
    "test_dir = args_data + '/test_images/mistery_category'\n",
    "\n",
    "\n",
    "output_file = open(args_outfile, \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "for f in tqdm(os.listdir(test_dir)):\n",
    "    if 'jpg' in f:\n",
    "        data = data_transforms(pil_loader(test_dir + '/' + f))\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "print(\"Succesfully wrote \" + args_outfile + ', you can upload this file to the kaggle competition website')\n",
    "\n",
    "# Check if output_file is available\n",
    "print('kaggle.csv' in os.listdir('./experiment/'))\n",
    "print(os.listdir('experiment'))\n",
    "\n",
    "# create a link to download the dataframe\n",
    "create_download_link(\"experiment/kaggle.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
