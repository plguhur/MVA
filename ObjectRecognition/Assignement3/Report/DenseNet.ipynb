{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "scrolled": true
      },
      "cell_type": "code",
      "source": "import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport re\nfrom tqdm import tqdm\nfrom IPython.display import HTML\nimport base64\nimport zipfile\nimport os\nimport PIL.Image as Image\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\n\nis_trained = True\n\ndef create_download_link(title=\"Download CSV file\", filename=\"experiment/kaggle.csv\"):\n    df = pd.read_csv(filename)\n    csv = df.to_csv(index=False)\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\n\ndef pil_loader(path):\n    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n    with open(path, 'rb') as f:\n        with Image.open(f) as img:\n            return img.convert('RGB')\n\n\ndef sample_image():\n    bird_classes = os.listdir('../input/bird_dataset/bird_dataset/train_images/')\n    sample_class = np.random.choice(bird_classes)\n    training_path = '../input/bird_dataset/bird_dataset/train_images/'\n    sample_image = np.random.choice(os.listdir(training_path+sample_class))\n    path_sample_image = training_path + sample_class + '/' + sample_image\n    x = plt.imread(path_sample_image)\n    return x\n\ndef train(epoch, model, train_loader, record_loss=True):\n    \"\"\"\n        Train the global defined model.\n        Warnings:\n            model: is a global variable here\n        Input:\n            epoch: The index number of the epoch (This is NOT the number of epochs)\n            record_loss: Record the loss evolution for the model\n    \"\"\"\n    # loss recording\n    loss_evolution = []\n\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        optimizer.zero_grad()\n        output = model(data)\n        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n        loss = criterion(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args_log_interval == 0:\n            loss_value = loss.data.item()\n            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx / len(train_loader), loss_value))\n        if record_loss:\n            loss_evolution.append(loss_value)\n\n    if record_loss:\n        return loss_evolution\n\ndef get_model(path_experiment, number=-1):\n    if number < 0:\n        model_names = os.listdir(path_experiment)\n        print(model_names)\n        model_numbers = []\n        for name in model_names:\n            regex = r'(\\d+)\\.pth'\n            pattern = re.compile(regex)\n            match = re.search(pattern, name)\n            if match is not None:\n                model_numbers.append(int(match.group(1)))\n        number = np.max(model_numbers)\n    return f'./experiment/model_{number}.pth'\n\n\ndef validation(model, val_loader):\n    \"\"\"\n        Compute validation score\n        Warnings:\n            As in train(), the model is a global variable definition\n        Input:\n        Output:\n            validation_loss <float>\n            accuracy <float>\n\n    \"\"\"\n    model.eval()\n    validation_loss = 0\n    correct = 0\n    for data, target in val_loader:\n        if use_cuda:\n            data, target = data.cuda(), target.cuda()\n        output = model(data)\n        # sum up batch loss\n        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n        validation_loss += criterion(output, target).data.item()\n        # get the index of the max log-probability\n        pred = output.data.max(1, keepdim=True)[1]\n        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n\n    validation_loss /= len(val_loader.dataset)\n    accuracy = 100. * correct / len(val_loader.dataset)\n    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n        validation_loss, correct, len(val_loader.dataset),\n        accuracy))\n\n    return validation_loss, accuracy\n\ndef adjust_learning_rate(learning_rate, optimizer, epoch, schedule=[150, 225], gamma=0.1):\n    if epoch in schedule:\n        learning_rate *= gamma\n        for param_group in optimizer.param_groups:\n            param_group['lr'] = learning_rate\n    return learning_rate\n\n# bird_classes = os.listdir('../input/mva-recvis-2018/bird_dataset/bird_dataset/train_images/')\nbird_classes = os.listdir('../input/bird_dataset/bird_dataset/train_images/')\nsample_class = np.random.choice(bird_classes)\ntraining_path = '../input/bird_dataset/bird_dataset/train_images/'\n\n# parameters\nn_classes = len(bird_classes)\n\nargs_data = '../input/bird_dataset/bird_dataset/'\nargs_seed = 1\nargs_log_interval = 10\nargs_experiment = 'experiment'\n\n# Create experiment folder\nif not os.path.isdir(args_experiment):\n    os.makedirs(args_experiment)\n    \nprint('Folder:')\nfor folder_ in os.listdir():\n    print('    /' + folder_)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e0295f750d7a2f4ea748386db844f0ce8b70771d"
      },
      "cell_type": "markdown",
      "source": "## Model"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "transform_train = transforms.Compose([\n#     transforms.RandomCrop(64, padding=4),\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n#     transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n    transforms.RandomAffine(degrees=0, scale=(0.8, 1.2), shear=None, resample=False, fillcolor=0),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\nargs_batch_size = 64\nargs_epochs = 300\nargs_lr = 0.1\nargs_weight_decay = 1e-4\nargs_momentum = 0.9\n\n            \nfrom torchvision.models.densenet import DenseNet\nmodel = DenseNet(growth_rate=12, num_classes=n_classes, drop_rate=0.1)#, block_config=(6,12,32,32))\n#         growth_rate (int) - how many filters to add each layer (`k` in paper)\n#         block_config (list of 4 ints) - how many layers in each pooling block\n#         num_init_features (int) - the number of filters to learn in the first convolution layer\n#         bn_size (int) - multiplicative factor for number of bottle neck layers\n#           (i.e. bn_size * k features in the bottleneck layer)\n#         drop_rate (float) - dropout rate after each dense layer\n#         num_classes (int) - number of classification classes",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "14174549b6cd60d23aef2f7fc45af7b1b2db38c5"
      },
      "cell_type": "markdown",
      "source": "## main.py"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "0dd61ae7a284df965c250550fa4a5bec164c648c"
      },
      "cell_type": "code",
      "source": "use_cuda = torch.cuda.is_available()\nif use_cuda:\n    model.cuda()\ntorch.manual_seed(args_seed)\n\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(args_data + '/train_images',\n                         transform=transform_train),\n    batch_size=args_batch_size, shuffle=True, num_workers=0)\n\nval_loader = torch.utils.data.DataLoader(\n    datasets.ImageFolder(args_data + '/val_images',\n                         transform=transform_test),\n    batch_size=args_batch_size, shuffle=False, num_workers=0)\n\noptimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum, weight_decay=args_weight_decay)\n# optimizer = torch.optim.Adam(model.parameters(), lr=args_lr)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "daf79614533e0d2ccc2441e07f77ed02bae3ad8d",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "# Go through epochs and record loss on training set and accuracy on\ntrain_loss_evolution = []\nvalid_loss_evolution = []\nvalid_accuracy_evolution = []\n\nif not is_trained:\n    for epoch in range(1, args_epochs + 1):\n        args_lr = adjust_learning_rate(args_lr, optimizer, epoch)\n        loss_evolution = train(epoch, model, train_loader, record_loss=True)\n        validation_loss, accuracy = validation(model, val_loader)\n        # Record\n        train_loss_evolution.append(loss_evolution)\n        valid_loss_evolution.append(validation_loss)\n        valid_accuracy_evolution.append(accuracy)\n\n        # Store the last 2 models\n        if epoch > args_epochs-2:\n            model_file = args_experiment + '/model_' + str(epoch) + '.pth'\n            torch.save(model.state_dict(), model_file)\n            print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "23a4f61dfe172a157f5c70697547bd0d4f5c786d"
      },
      "cell_type": "markdown",
      "source": "#### Visualise loss and accuracy evolutions"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e45a462b5ed206f97147a0d1edadea5814baf207"
      },
      "cell_type": "code",
      "source": "if not is_trained:\n    plt.figure(figsize=(15,15))\n\n    plt.subplot('311')\n    plt.title('Evolution of the training loss')\n    plt.plot(np.mean(np.array(train_loss_evolution), axis=1), alpha=0.4, label='mean')\n    plt.plot(np.mean(np.array(train_loss_evolution), axis=1) + 3*np.std(np.array(train_loss_evolution), axis=1), 'rs--', alpha=0.4 ,label='std_bound')\n    plt.plot(np.mean(np.array(train_loss_evolution), axis=1) - 3*np.std(np.array(train_loss_evolution), axis=1), 'rs--', alpha=0.4)\n    plt.boxplot(np.array(train_loss_evolution).T)\n    plt.xlabel('epochs')\n    plt.ylabel('validation loss')\n    plt.legend()\n    plt.grid()\n\n    plt.subplot('312')\n    plt.title('Validation loss evolution')\n    plt.plot(np.array(valid_loss_evolution), 'xk')\n    plt.plot(np.array(valid_loss_evolution), 'k--', alpha=0.4)\n\n    plt.grid()\n\n    plt.subplot('313')\n    plt.title('Validation accuracy evolution')\n    plt.plot(np.array(valid_accuracy_evolution), 'xk')\n    plt.plot(np.array(valid_accuracy_evolution), 'k--', alpha=0.4)\n    plt.grid()\n\n    plt.show()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8a9484c0fafea152ce807573bc95759d9242fe6c"
      },
      "cell_type": "markdown",
      "source": "## Evaluate"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "bbc77f5d473900bb94b1f2f28d2f31a283506ecc"
      },
      "cell_type": "code",
      "source": "args_outfile = os.path.join(args_experiment, 'kaggle.csv')\nargs_model = get_model(args_experiment)\n\nstate_dict = torch.load(args_model)\n# model = Net()\nmodel.load_state_dict(state_dict)\nmodel.eval()\nif use_cuda:\n    model.cuda()\n\ntest_dir = args_data + '/test_images/mistery_category'\n\n\noutput_file = open(args_outfile, \"w\")\noutput_file.write(\"Id,Category\\n\")\nfor f in tqdm(os.listdir(test_dir)):\n    if 'jpg' in f:\n        data = transform_test(pil_loader(test_dir + '/' + f))\n        data = data.view(1, data.size(0), data.size(1), data.size(2))\n        if use_cuda:\n            data = data.cuda()\n        output = model(data)\n        pred = output.data.max(1, keepdim=True)[1]\n        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n\noutput_file.close()\n\nprint(\"Succesfully wrote \" + args_outfile + ', you can upload this file to the kaggle competition website')\n\n# Check if output_file is available\nprint('kaggle.csv' in os.listdir('./experiment/'))\nprint(os.listdir('experiment'))\n\n# create a link to download the dataframe\ncreate_download_link('experiment/kaggle.csv')\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c6491ac8c8c8bcc42a617e2c72e608cd4bcaf5eb"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}