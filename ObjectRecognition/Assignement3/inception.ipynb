{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from IPython.display import HTML\n",
    "import base64\n",
    "import zipfile\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "is_trained = False\n",
    "\n",
    "def create_download_link(title=\"Download CSV file\", filename=\"experiment/kaggle.csv\"):\n",
    "    df = pd.read_csv(filename)\n",
    "    csv = df.to_csv(index=False)\n",
    "    b64 = base64.b64encode(csv.encode())\n",
    "    payload = b64.decode()\n",
    "    html = '<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n",
    "    html = html.format(payload=payload,title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "\n",
    "def sample_image():\n",
    "    bird_classes = os.listdir('../input/bird_dataset/bird_dataset/train_images/')\n",
    "    sample_class = np.random.choice(bird_classes)\n",
    "    training_path = '../input/bird_dataset/bird_dataset/train_images/'\n",
    "    sample_image = np.random.choice(os.listdir(training_path+sample_class))\n",
    "    path_sample_image = training_path + sample_class + '/' + sample_image\n",
    "    x = plt.imread(path_sample_image)\n",
    "    return x\n",
    "\n",
    "def train(epoch, model, train_loader, record_loss=True):\n",
    "    \"\"\"\n",
    "        Train the global defined model.\n",
    "        Warnings:\n",
    "            model: is a global variable here\n",
    "        Input:\n",
    "            epoch: The index number of the epoch (This is NOT the number of epochs)\n",
    "            record_loss: Record the loss evolution for the model\n",
    "    \"\"\"\n",
    "    # loss recording\n",
    "    loss_evolution = []\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % args_log_interval == 0:\n",
    "            loss_value = loss.data.item()\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss_value))\n",
    "        if record_loss:\n",
    "            loss_evolution.append(loss_value)\n",
    "\n",
    "    if record_loss:\n",
    "        return loss_evolution\n",
    "\n",
    "def get_model(path_experiment, number=-1):\n",
    "    if number < 0:\n",
    "        model_names = os.listdir(path_experiment)\n",
    "        print(model_names)\n",
    "        model_numbers = []\n",
    "        for name in model_names:\n",
    "            regex = r'(\\d+)\\.pth'\n",
    "            pattern = re.compile(regex)\n",
    "            match = re.search(pattern, name)\n",
    "            if match is not None:\n",
    "                model_numbers.append(int(match.group(1)))\n",
    "        number = np.max(model_numbers)\n",
    "    return f'./experiment/model_{number}.pth'\n",
    "\n",
    "\n",
    "def validation(model, val_loader):\n",
    "    \"\"\"\n",
    "        Compute validation score\n",
    "        Warnings:\n",
    "            As in train(), the model is a global variable definition\n",
    "        Input:\n",
    "        Output:\n",
    "            validation_loss <float>\n",
    "            accuracy <float>\n",
    "\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='elementwise_mean')\n",
    "        validation_loss += criterion(output, target).data.item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    accuracy = 100. * correct / len(val_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        accuracy))\n",
    "\n",
    "    return validation_loss, accuracy\n",
    "\n",
    "def adjust_learning_rate(learning_rate, optimizer, epoch, schedule=[150, 225], gamma=0.1):\n",
    "    if epoch in schedule:\n",
    "        learning_rate *= gamma\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = learning_rate\n",
    "    return learning_rate\n",
    "\n",
    "\n",
    "args_data = 'bird_dataset/'\n",
    "training_path = os.path.join(args_data, 'train_images')\n",
    "bird_classes = os.listdir(training_path)\n",
    "sample_class = np.random.choice(bird_classes)\n",
    "\n",
    "# parameters\n",
    "n_classes = len(bird_classes)\n",
    "args_seed = 1\n",
    "args_log_interval = 10\n",
    "args_experiment = 'experiment'\n",
    "\n",
    "# Create experiment folder\n",
    "if not os.path.isdir(args_experiment):\n",
    "    os.makedirs(args_experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e0295f750d7a2f4ea748386db844f0ce8b70771d"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "#     transforms.RandomCrop(64, padding=4),\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "#     transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "args_batch_size = 64\n",
    "args_epochs = 200\n",
    "args_lr = 0.1\n",
    "args_weight_decay = 1e-4\n",
    "args_momentum = 0.9\n",
    "\n",
    "            \n",
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "__all__ = ['InceptionV4', 'inceptionv4']\n",
    "\n",
    "model_urls = {\n",
    "    'inceptionv4': 'https://s3.amazonaws.com/pytorch/models/inceptionv4-58153ba9.pth'\n",
    "}\n",
    "\n",
    "class BasicConv2d(nn.Module):\n",
    "\n",
    "    def __init__(self, in_planes, out_planes, kernel_size, stride, padding=0):\n",
    "        super(BasicConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, bias=False) # verify bias false\n",
    "        self.bn = nn.BatchNorm2d(out_planes, eps=0.001, momentum=0, affine=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class Mixed_3a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_3a, self).__init__()\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "        self.conv = BasicConv2d(64, 96, kernel_size=3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.maxpool(x)\n",
    "        x1 = self.conv(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "class Mixed_4a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_4a, self).__init__()\n",
    "\n",
    "        self.block0 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1)\n",
    "        )\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            BasicConv2d(160, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 64, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(64, 64, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(64, 96, kernel_size=(3,3), stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.block0(x)\n",
    "        x1 = self.block1(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "class Mixed_5a(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Mixed_5a, self).__init__()\n",
    "        self.conv = BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        self.maxpool = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv(x)\n",
    "        x1 = self.maxpool(x)\n",
    "        out = torch.cat((x0, x1), 1)\n",
    "        return out\n",
    "\n",
    "class Inception_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_A, self).__init__()\n",
    "        self.block0 = BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            BasicConv2d(384, 64, kernel_size=1, stride=1),\n",
    "            BasicConv2d(64, 96, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(96, 96, kernel_size=3, stride=1, padding=1)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(384, 96, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.block0(x)\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x)\n",
    "        x3 = self.block3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "class Reduction_A(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_A, self).__init__()\n",
    "        self.block0 = BasicConv2d(384, 384, kernel_size=3, stride=2)\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            BasicConv2d(384, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=3, stride=1, padding=1),\n",
    "            BasicConv2d(224, 256, kernel_size=3, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.block2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.block0(x)\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "class Inception_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_B, self).__init__()\n",
    "        self.block0 = BasicConv2d(1024, 384, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.block1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(224, 256, kernel_size=(7,1), stride=1, padding=(3,0))\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(192, 224, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(224, 224, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(224, 256, kernel_size=(1,7), stride=1, padding=(0,3))\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1024, 128, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.block0(x)\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x)\n",
    "        x3 = self.block3(x)\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "class Reduction_B(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Reduction_B, self).__init__()\n",
    "\n",
    "        self.block0 = nn.Sequential(\n",
    "            BasicConv2d(1024, 192, kernel_size=1, stride=1),\n",
    "            BasicConv2d(192, 192, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            BasicConv2d(1024, 256, kernel_size=1, stride=1),\n",
    "            BasicConv2d(256, 256, kernel_size=(1,7), stride=1, padding=(0,3)),\n",
    "            BasicConv2d(256, 320, kernel_size=(7,1), stride=1, padding=(3,0)),\n",
    "            BasicConv2d(320, 320, kernel_size=3, stride=2)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.MaxPool2d(3, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.block0(x)\n",
    "        x1 = self.block1(x)\n",
    "        x2 = self.block2(x)\n",
    "        out = torch.cat((x0, x1, x2), 1)\n",
    "        return out\n",
    "\n",
    "class Inception_C(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Inception_C, self).__init__()\n",
    "        self.block0 = BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "        \n",
    "        self.block1_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.block1_1a = BasicConv2d(384, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.block1_1b = BasicConv2d(384, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        \n",
    "        self.block2_0 = BasicConv2d(1536, 384, kernel_size=1, stride=1)\n",
    "        self.block2_1 = BasicConv2d(384, 448, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        self.block2_2 = BasicConv2d(448, 512, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.block2_3a = BasicConv2d(512, 256, kernel_size=(1,3), stride=1, padding=(0,1))\n",
    "        self.block2_3b = BasicConv2d(512, 256, kernel_size=(3,1), stride=1, padding=(1,0))\n",
    "        \n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.AvgPool2d(3, stride=1, padding=1, count_include_pad=False),\n",
    "            BasicConv2d(1536, 256, kernel_size=1, stride=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.block0(x)\n",
    "        \n",
    "        x1_0 = self.block1_0(x)\n",
    "        x1_1a = self.block1_1a(x1_0)\n",
    "        x1_1b = self.block1_1b(x1_0)\n",
    "        x1 = torch.cat((x1_1a, x1_1b), 1)\n",
    "\n",
    "        x2_0 = self.block2_0(x)\n",
    "        x2_1 = self.block2_1(x2_0)\n",
    "        x2_2 = self.block2_2(x2_1)\n",
    "        x2_3a = self.block2_3a(x2_2)\n",
    "        x2_3b = self.block2_3b(x2_2)\n",
    "        x2 = torch.cat((x2_3a, x2_3b), 1)\n",
    "\n",
    "        x3 = self.block3(x)\n",
    "\n",
    "        out = torch.cat((x0, x1, x2, x3), 1)\n",
    "        return out\n",
    "\n",
    "class InceptionV4(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=1001):\n",
    "        super(InceptionV4, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            BasicConv2d(3, 32, kernel_size=3, stride=2),\n",
    "            BasicConv2d(32, 32, kernel_size=3, stride=1),\n",
    "            BasicConv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            Mixed_3a(),\n",
    "            Mixed_4a(),\n",
    "            Mixed_5a(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Inception_A(),\n",
    "            Reduction_A(), # Mixed_6a\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Inception_B(),\n",
    "            Reduction_B(), # Mixed_7a\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            Inception_C(),\n",
    "            nn.AvgPool2d(8, count_include_pad=False)\n",
    "        )\n",
    "        self.classif = nn.Linear(1536, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classif(x) \n",
    "        return x\n",
    "\n",
    "\n",
    "def inceptionv4(pretrained=False):\n",
    "    r\"\"\"InceptionV4 model architecture from the\n",
    "    `\"Inception-v4, Inception-ResNet...\" <https://arxiv.org/abs/1602.07261>`_ paper.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = InceptionV4()\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['inceptionv4']))\n",
    "    return model\n",
    "\n",
    "model = inceptionv4(pretrained=True)\n",
    "model.aux_logit=False\n",
    "in_features = model.classif.in_features\n",
    "model.fc = nn.Linear(in_features, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14174549b6cd60d23aef2f7fc45af7b1b2db38c5"
   },
   "source": [
    "## main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "0dd61ae7a284df965c250550fa4a5bec164c648c"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    model.cuda()\n",
    "torch.manual_seed(args_seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(args_data + '/train_images',\n",
    "                         transform=transform_train),\n",
    "    batch_size=args_batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(args_data + '/val_images',\n",
    "                         transform=transform_test),\n",
    "    batch_size=args_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=args_lr, momentum=args_momentum, weight_decay=args_weight_decay)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=args_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "daf79614533e0d2ccc2441e07f77ed02bae3ad8d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go through epochs and record loss on training set and accuracy on\n",
    "train_loss_evolution = []\n",
    "valid_loss_evolution = []\n",
    "valid_accuracy_evolution = []\n",
    "\n",
    "if not is_trained:\n",
    "    for epoch in range(1, args_epochs + 1):\n",
    "        args_lr = adjust_learning_rate(args_lr, optimizer, epoch)\n",
    "        loss_evolution = train(epoch, model, train_loader, record_loss=True)\n",
    "        validation_loss, accuracy = validation(model, val_loader)\n",
    "        # Record\n",
    "        train_loss_evolution.append(loss_evolution)\n",
    "        valid_loss_evolution.append(validation_loss)\n",
    "        valid_accuracy_evolution.append(accuracy)\n",
    "\n",
    "        # Store the last 2 models\n",
    "        if epoch > args_epochs-2:\n",
    "            model_file = args_experiment + '/model_' + str(epoch) + '.pth'\n",
    "            torch.save(model.state_dict(), model_file)\n",
    "            print('\\nSaved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23a4f61dfe172a157f5c70697547bd0d4f5c786d"
   },
   "source": [
    "#### Visualise loss and accuracy evolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e45a462b5ed206f97147a0d1edadea5814baf207"
   },
   "outputs": [],
   "source": [
    "if not is_trained:\n",
    "    plt.figure(figsize=(15,15))\n",
    "\n",
    "    plt.subplot('311')\n",
    "    plt.title('Evolution of the training loss')\n",
    "    plt.plot(np.mean(np.array(train_loss_evolution), axis=1), alpha=0.4, label='mean')\n",
    "    plt.plot(np.mean(np.array(train_loss_evolution), axis=1) + 3*np.std(np.array(train_loss_evolution), axis=1), 'rs--', alpha=0.4 ,label='std_bound')\n",
    "    plt.plot(np.mean(np.array(train_loss_evolution), axis=1) - 3*np.std(np.array(train_loss_evolution), axis=1), 'rs--', alpha=0.4)\n",
    "    plt.boxplot(np.array(train_loss_evolution).T)\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('validation loss')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot('312')\n",
    "    plt.title('Validation loss evolution')\n",
    "    plt.plot(np.array(valid_loss_evolution), 'xk')\n",
    "    plt.plot(np.array(valid_loss_evolution), 'k--', alpha=0.4)\n",
    "\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot('313')\n",
    "    plt.title('Validation accuracy evolution')\n",
    "    plt.plot(np.array(valid_accuracy_evolution), 'xk')\n",
    "    plt.plot(np.array(valid_accuracy_evolution), 'k--', alpha=0.4)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a9484c0fafea152ce807573bc95759d9242fe6c"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "bbc77f5d473900bb94b1f2f28d2f31a283506ecc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517/517 [12:16<00:00,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succesfully wrote experiment/kaggle.csv, you can upload this file to the kaggle competition website\n",
      "True\n",
      "['model_3.pth', 'model_2.pth', 'model_1.pth', 'model_5.pth', 'model_4.pth', 'model_6.pth', 'model_7.pth', 'kaggle.csv', 'model_10.pth', 'model_9.pth', 'model_8.pth']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a download=\"experiment/kaggle.csv\" href=\"data:text/csv;base64,Id,Category
f797dafedeabc2cd79aa730d029bd09b,732
ebc9d3eac76dc9fcd450b312f1feace9,732
20e309627aaf97e0fee50a39a434c2bf,464
f530b89a6486d5cc8fe20cf1178ff150,732
37abcbdb3bca852ee853c48fbd0f2d73,464
47f6849caa9f6f62464a0c9a6e80d51f,732
31e7782137785c3f93d141c4f1ae4a36,732
bbe0a4e68ded4b91ac7f5b19d811e0ec,732
c8ec34cf7ee54d51bb632a53d89f5c56,732
90bf0ec139471e076020fc8aed9b2576,464
d08b43687503170c36402386df6a490f,732
90a9fb69900186f5aadd53e7790b1cab,732
7dcf5624066b67a29f423a8071fcd984,732
c9c889facf5f109cf1b1fb68ced2a0e1,732
42b7c8172fdfbb86e9ed7139d3db3ddd,732
a52ab6ca2ec1dcd0e4834c50bb69cb3f,357
f11ec871f7ebefe5731d487b6a7854cc,732
ca4b49237d0803abbb845d6d3d515ad5,732
574f7b42ff837a315406e6340d0fc54b,464
9d7754cd63d0c2ef4114705a37443547,732
3091bb2374374f0ed34faed50815ae12,732
87bb8c5543cc059593997ff27601b1f2,732
1f5074135fcf27f86c32db0d76fa0453,732
002f61512a368e4c1434eedacf609957,732
4a2fa1c8e573558b1534a1c0802571c7,464
f4330d0d109de59e306824bd55628742,732
d8fee3d831aea2e61aacd9d429ce4d55,732
03b5b072b80ec04df1dee668f44abad4,732
4836bedeec2a2617ee33922ebf89995a,732
0c0dc45bee119911746c9a77db283873,732
6b07f85c04e8485623ee984d132c7a79,464
3b567146f9148617c5fbed9b346e5bb1,464
6ebdc52674fa9872a716060f4353b6fb,464
d18c1c9b2849e5f77c2bc250635f0d95,732
a0f6155272926ff2f81a47ac67333937,732
2507bf470255a2d6de414439a980855c,732
cadb9e4da9f48919c21082ab9e948ceb,732
2c74d6d419c534a701d39f7cd5b44c52,853
26de142b595665bf7540d0526012608b,732
035f7f6b1a162d86bb4755e6558f33d9,732
111330b5f487ba9a585572e1544f1507,464
703315c52c662c32732bed3a90925817,732
08f5a56753a26fac59c451aa50d545f4,732
cb7c71c88ac180d44b580813a7167b6d,732
70fddb3c64b44a4d43e32a7c8148c425,732
fd5f28cd072603cb6e03c6e011808c0e,732
a09078a10a1de9952263672b5a5d6935,732
d5915b969c77177c90c6f2f6748c17d6,464
f093b8d142b73f532ea6869f13edcb2e,732
7c86b6e08fa21fcf092b402dffcf2117,732
e88979a6b2b8fa4fde40bc89fadb41de,853
130189af6e37c7d4620cc67dcab79699,732
100f3192f436325a28debb8d07a5e725,732
ffe6dc708419b819ea897d666e986ec6,732
81b40058b64df85c845a3936c337c586,732
df50119e60bb5673cf07a19c41a8e481,732
826996758001c20cffd5fb3016a811cf,732
465ce159f0171470a282655d369bdc53,732
90dab576ce9a913ef8faced7adf48b4f,732
64f3fa85502e9cff91d6dc88f54be7cb,524
e98ecdaa7f147f641b379771920aa004,732
20eccc6210f9529e5b0180dd47108881,732
442a1034a34bcb93e8a49cd1a68fccdb,732
3acd266712962940976cbacbeb17a513,732
40e9db9adb495ba227987128f4506d87,732
56e4971212cb203c27f24a81ec8e5e7d,732
679d31eb7b0f08ba888b20f838084d08,732
ce1028221704ba6e933f4269faad92ed,732
baa2c60049e8a78e511faf8e591baac7,732
dfd9f5d2e5ddfe20514f07832bab2602,732
0cf49df5e4eeb368d765c75317298394,732
e553a25b8308b91598504b40025112e0,732
b4b2bb2d96768ef960b53ffc3b3e7d1b,732
139dd3b6d1034be20cff38318105d08b,732
68d1869f8a19e3d79cb77ff6fe36ab8d,732
f02d6db37917adaf898f4af0362f1bb2,732
409916784b3e672d1702b39fa50cf013,732
800d15192f06a35458fd0c5d64ef59b5,732
66b4e2665ab671f2dced94770475659c,732
748b034fbeb69533a9890ce1026b4dcc,732
26aaadb293e40df6f135721b3f3637ce,464
19d7371028e1625fb30cccf0abc56ad6,732
c838e8090064966e460265057091f3d1,732
baa237f0968b7c0b62f951979e6e4053,732
7e07e19a08c1630ac4d556e7412a31fc,732
0a744c3378ef4ec70f4841e283934103,732
46a1fe86e0f64c627a2031610afff5e5,732
5c1d17bfbf543407b28d6a2f7932410c,732
7c18125deb9cddeba47c720635c87533,732
2f0b126e2755fffd2c53ba5fc4687a67,732
e30e4f62cc4f88968ddf35e9624e48fe,464
6e3c2c583774606210735e93fda8a521,732
5f0aef4d606f71aa4f2a540818937de5,732
4844a713043c515f66a97dc3b319ad65,732
a8c9c24429dee5daf87b28661e2ad9eb,464
4be1c9d279c7c7a9e1f8774b6158fb96,732
099b8cdf2b51401c0a7b5b43d9e967c0,732
171ad3981fafded4676f5b021377961f,464
f341204709b662fdbb4800902cad9df0,732
f4b1b183c44bbad9289b1da4d7896ee7,732
5c42c351dcc9d6f372d17b39b6a27860,464
31a725674a21f85f1d79cf1236bf5e67,734
e7fdcb0c0434c54f7f82c1b3e6ab4999,732
127efbd89465dc70150d7e440a0d0d1d,732
82677bf899f365fce754816c602fb8db,732
ebe8d00db671bdbb349879a82a3ce490,732
6e2110dd12136a681b2dd32fff190e90,732
866f2c4a13bcd4f399202301cf72ff72,732
fd0af389dcb3749670bd1cebd085fb85,734
529cbb5884798ea09c3cb9d5a90aec59,732
64302e7bfb63c6665d1f5be6615ff714,732
958a765e4a60521e1dea9db1f03961e8,732
55d965bd3cc40f82d8eca35d2cf7a04e,732
dea9f7b9dfbecd7015d16ab980176e6b,732
eac387ffc0e152a5d2934e95ba7a3097,732
e51ad12ab2a8fe2cb645c92964c7df8f,732
b8e4200b831bbd37bfff150418c4c29b,732
f647602f147dce978d4a01019f88e4d2,732
65f3d67b186fd22b5c0e84b2df63f10c,732
e174e2603923612545b985be528ebeb0,464
db67ca52c20e0e15280a38011d4029c2,732
e708d232dc7d3c6234be66455375b916,732
d011945315676022fa420f46a4750842,732
e79f50d3f77b75d5351d814eb47d4d77,732
8a6da494de49b6897781454488848cf1,732
e179ba3451e37f5bd63062b1087dd0a9,853
bd6b90652602e1b6abe53d991544a1dd,464
dcd70f3ea711017dae33bdc30445aba0,732
cde3554433d0e297c17c74c9b243f47c,732
c2c494a74bfb7ca6c211683b231ccf9c,732
222b70d1944b7bb50b41c93962535967,732
57cdd6f0a11c02e93b41d636bcaf04a4,732
b24bc52ab47781ccd5162c9a462741e0,732
b936a98be5409db37f27bac20bee4ddd,464
e49efcb51517beaff3f4f1e631d9d3b7,732
43830884025146cf1bb483cf35af1fca,732
769f399ad73cd5c4983a4a42be8ef2d6,732
6b152adc407f6fcb6e9438cd6cbd6327,732
532bdf3560359a3be1988d9e68bd39b1,732
daff1aac7d1ea417939db6e7fc56428e,732
83a5afccfd69121b1fa338d5f37379a1,732
9a50e05daf45aa3a42a088c02957dc6d,732
7d034e41ab158f465de70b3270cdb69c,732
ad08ba64f41b7c50feb7701489a25fc9,732
51075115bd925c20045f9e4e65df914e,732
d3439d774ce2071f95b8809fc52a0515,464
940402f0b4f0168e8a9172382e0471c9,464
b5f42249b850a24446a7ff0ef286e487,732
310e9b061b6047047c3c503bc978a075,601
c953417f87df9a3d4e1f3be905c26a2c,732
77059b120dae3d33712322af77fb2c9c,732
f0fd665607c8b4c18ccbdebdd3d1931e,464
e0d5d8f7658e9e7d9cfb33f434a1a36c,853
b41bdb5f6b1464534c3d0575bc3365f8,732
5e0604bc219aad1504ff42341334bd34,464
584fb865fbd41948c0fd3750923b29c3,464
368b4bd2c77a11ea4c2943d048f644f6,464
1e8373fa23f94002d192378a39dfb527,732
debdd05c4a5cfc1ea008e040ca64fc30,732
a34d33333c18da1258e790c60f2b07a2,732
da9aa4eaae3ec62de9195ae742dcf2ad,732
b193593ec3ccc440508145cae0ef086e,732
a90097b8ebc1a7ffd5eecf31fd9560ce,732
0247efd7b9d47d036bb4390202a13e69,732
de690e9504ff0f1c63eb9381defd0390,464
f2870d5dd6b0ee205d960781c0d7d68f,732
45abe39f83c9f5e0d7c1fe5162e655d6,732
5bf1d328b7f5cd9f0c6fdfc8fe8a5c23,732
6ba14489a2ada442cd9e511a89f289d9,601
8f05bf8e4f93260959d9bad3ee71bee9,732
46625438b1822c4b527c47bbf579ee4c,732
56b37b15cfcd97ba9db333ac6d8a8b61,732
88549604f02092db2d9a4777c7477856,732
1e214cfa62f74928d7ea5d5c5c35ca93,464
27dd99701aa393344c1c15345b319692,464
cdc8295f4e43d1a69eedb35020489612,732
688b5ba8ac00564557c3febc3055a9df,464
3151f1530e7c0cb6196e494c15eb493b,732
f003abbdf9329f5f631e4c040b9f0d3c,732
9b80d1dfefe4c15256fe0ed20da0f614,732
cd024f81608ba787e1710652e2057e8c,732
034abbbb69336b0de7c7c0f2aa1267a6,732
f112a4a7936483f41e365309ad44d27a,732
5526ea87142b4a88ee4eb2803e2b9bdf,464
e62dc4014cb2d5283d9667cf8b7ea594,732
26ebb64db86247606e4f983712d43359,732
b5316c8e51b97debf6420b34325ec114,732
038872d6dfc340d0ff11f8d3c99d026e,732
5234cf2f3c0dd8f92a36394a591c7ce1,732
96bc6f12934c2c546ed4d6ddd5dd887c,464
125f6d101a92e7a7eabb2a45fe233f34,732
25055c9c032445c402baf5e222bfb9e2,732
abcc98b6b79b4352afa940f749130013,464
9d8264c3393f849298c0642add7f00ea,732
316f7838d482915e1b514c32ade3d5e8,853
337494959c5325d7b1f785d41e084f26,732
b3ad8445a3ce068343ec95f395cf1d24,732
f540d62813721058081c65c41a9cb0dc,732
8992398fc52adf23d2549459d92c160c,732
948f7030daa5e98b8f183bc7e5507923,464
f9004ef97c205c58637c053d69f8ed41,601
43fe3a09f2c7ccd2f97888f341ad20ba,464
a3a5f7837055db69f10649dd7cf6a92c,732
e7833a463fb9af679227107a3c36682c,464
c543a15f07efc84b5f5030261f0f693c,732
97a9bdf7f7c32a8b07d4dfbd288bc2d0,732
99888f22e9e4a17cac0fcf4d39352640,732
11b8a8e9a432067a19c43ede5b06fa3b,732
85b096104cfa5ff9bb4bfea171d87208,732
18783b75d07abcf7c8a77f5bdb28751e,732
2d10d7738ad31d29bdfd45e734ae320f,732
e03a8b03c1edb34b1f31b56b386a6101,732
e40d7292f81ad017e50b9bd9ad7f4c13,732
b77bedbe9c27d1983d1151c7dd17c7e0,732
ff5bdc3866e4fda1396030b9a146c19d,464
a05ed5dd6cbd3097e81e3c76ac690465,732
59e5a4b2bde751759781096894b0b2af,732
226cd33fa66e7d7ed28a357e1a3ae3d4,732
b5d6727992a8838847533b791915de2e,732
442c380bbae32987b1f950ab8c488136,732
8b26651325df8fb1462dcbb20bf7994d,464
896807af0f5df0d664e003daa58fdf74,732
75bda85923f3eb3d8338cb2d42339330,732
7e05c5a79f9319f8a8a99548d2f7f954,464
0267548c2aac82fe3d7e37ae98b00bd7,732
b5b4274be0ac2d31944346addb3dfdab,732
3e619cc5303b8404c8ee5d595f87fb34,732
41a4f6b345f3825e3e9087df479184c7,464
67205b632b48719f20262c8186e675cd,732
8bc479269fec2a7eae40385119c2ee49,732
f5a41d1b7638af9e2f3e1db1622364fd,732
8a893a972e6eb562e1383f9df0adb777,464
5db472b43f5627d4968c40a33278734c,464
29b6afd0efda72d10998fbce2c3ccf9f,732
ce85bf0371009d7b98cbd0828726b35a,732
82beb15112d018734c565561bfe231a3,732
770ad07a0ff2092dae44f6ebec9c9886,732
c95b3a75971c8aed3695a778c3b36bb6,464
cb0ee3db495366b1bac47eecfb07fc26,732
f68ddbd9e9b35c5b2778394868577b71,464
88c986cf6e0a2dbee74605d4025cbd8f,732
3828cdb69f9ce6a1fad0e65c746f83cd,732
87dd88ffd7d686e0cde0aec31f66026c,732
d978fd0d4493f87241f805866d1fe5fa,732
42c8cb49c2f0f6b74e04d1566678b19c,464
817d22ad1bd54ef9311f3cc70083530a,732
1a8bb12e211c86d35ac8105e74e616ee,732
8970716e0bdf666242dade373592439f,732
b6093337ef2a45c4366995b2874ca554,732
def9c02fb41a0ef12cf4835e5fa87bbf,464
c2571a1237f1136dd5a32b67ee0d695f,732
32a10ccf60740ed405e80a85d5c9e2d5,732
f18bbe48a8ebf57958effb02eec3aa7b,732
cc17c00e53ba71456ca41f2ce568e87e,732
dea78880b447d7db1d776b2045b6f036,732
1b62fffcbf47a4f9e32b400edc662f1f,464
39e68ff4d8328512dfb6a62a19faafab,732
39a3b1946cd7a7bb89834beb4828cbba,464
4e7e72cbf3b0c9259dea6fc6601786b6,732
80603199e49605b8db742df76e7cb418,732
eb6be750d27e6031a2d03b7c40a6fc94,732
8a94c643402bd103bb29e4ad2c7f4e78,732
6ad5bf7135e35a3ed5d3f34013024a1f,732
756abfdacb3a7d798b5ece398bef33e3,732
99924fde6fd5f81c75e3c0468d9f72a8,732
54363d1f493ec8774f6d46cadce531cc,464
12378a28a80293aa1fc3cda41a7c187b,732
78906c453cbfeb9647ab0591b7da430f,464
73bf9a74144b55e6e716add70398ebf5,732
77703b27dc560baa58cfb3c714f577e6,732
6edea463a50c585a838dd6608cc0e03b,853
4d0abdf25ded6709040bb1a9a41edfbe,732
493f81135b862db618be038a740031b5,732
1d901287dd62656c8089234dbb88d732,464
64ea0c5fc9a4085ea5f133d767444a8f,464
8e0e6ebaf27e74100b27c3e32119b4a7,732
9639dd1d3079304856f3f8ec308deb5b,732
2efc116c0c094412e79da815696387e4,732
a51a4c5800059d2df30e273bafe71175,209
3fdb64bb7f134aed6e5995f879b3bb71,732
0676b04fc9527343bee8ae5a2a9d4692,732
d0b65a2c991c70f6000bae1efe30c27b,732
7dfe6c7a6d93ea21c0b715fca04c63ed,732
5ff7046848770cd6a7847b477fb59c20,732
57e0aecd931044c03adde0ff6e944b4c,732
a580c6d4deb63c696640e089b6238ce7,732
5aab3de502e7501c9189d17cd0ca928b,464
7c7dda90bde492d9f1b4bd3aa2e8de58,732
21ae3a0177f9e80c91d0c92395b2bd7a,464
5fa5bfe4f4002b53316e9f29a7ef09e7,732
0ab685b1515b7d4c76691e8373a65f47,464
d50158395fdfdedcdd59ab6db5201e99,732
9a7a7125ce4c62052960248b59be470c,853
7fbcd92ee0a480ae7675eccbb30a2124,732
1f18abbf61f6377ef26100fc26edeedc,732
507ac1dc34021ef82d8a91d5347a8ad4,732
3deb505285161e32927fc0bc3b7da8cd,732
971d707b8686c641fc40972a74186879,732
2307cf93ce6ab2ab6d91a32ff9f4067b,732
44de0bd6c46bcc2adc754188bb6ab142,732
3bf573af80e7c06cbd74978bfa587fb8,732
4edeccbcc5541a233750653b27177f13,853
518b04e5ff71aa69c32c72a7cf1bbff6,732
aaa7e3aaebb5678b56d9d1cd1a616eab,732
a2706ca5c2d1e8af4c1698e44987c5ed,732
724120169552f831a8e17ea8ce8447a4,732
bc5a3f2051ff60264dd535eb97a43b9f,732
e91036d19fbb50e3df6ccf61728abefa,732
bc92e79bfbf1434963f1364ffbda7dec,464
71c09173d97cb98fa373913f1e71d966,732
b608a78a0a6cf9ff6527e0cc2886cf95,732
d1c3426bbca3c249ea0ab1d0caa2e7d6,732
4ac18803f100031f5f87c1b78d62049c,732
c3d803d7a201f9bc357c01dc36a4a786,464
ee592ccc9591f81961cf05ba2296316c,732
6c70e36afde2a2f31826e21d74c2740d,464
ecca20075dc30f33bd55b681a9488f1d,732
2698cb89bccf6a5f4b29425f5f573f66,732
aef5fa6068d07e1ae739f35e3166b175,732
436b2347142a6e5cbc373fdc64836d4a,732
27fd211874ea7a6e0e741d0dcfc7b6b7,732
e7929803ee66f3b91f15f7e1e76ca3f6,732
09908286566fd3824e2db5d7fb2826b5,732
f687ba8db3e512863af57b7281687559,732
0b7b64c3eeae20e8f71923914a8643ef,732
f81b5d23407ed54fa3a99ed29fcda1a0,732
b9c1ac6d6d2843b496ee0998e4c81595,732
105a949eb4533e569f8fb6fdf220ff7f,464
c17c93833fa2b4d56509478c4ca0a98d,732
64366faff8ea6c08416a2b6a99e8801e,732
6acc98722be2e78bd70aa84f648fd0e5,464
5ea2538b1c3de10033672caf79a13074,732
5c49d532abde454dc109669ae5594916,732
911a1f5affcd2ee7490288765a785281,732
e608121a156b31be8799d2d640cfac8c,732
0910f1d5badf42de1aa9bae05037412d,732
6215a569fc29c911b2798831427aeb62,732
4dd33eb8e7500905866f3067e11535e4,732
4d37a50935575d523103250da65cc5e8,601
ceae4443a7365162fe3bea879c4b2776,464
71a8d323ba672e77c3b86d59f8a279a1,732
d716f3a09d7a8efa0ccac70d81b3b503,732
bc27f534edd690cffdb07f3b314c44c3,732
4e7f62c679f52732398143afcd3d11a1,732
23973ce106416044fd4133e2177273fe,732
9f8a20b1f7342c68de395d82559b2542,732
fb97b3a7197b6f5f856782d39fa14f49,732
c5faf9f2c691dbd50566fd0cd4e20276,732
176e2ea6dbe51d098aa87adaacae6fd8,732
8064ad6e67047772008ef4320d1515d4,732
8c5b5c02769e3e1788fdaf8d27ec4a0a,732
a65445216a669d870645f669ba2438e1,732
fa3db38c68c70898714a17ca83774158,732
81ab4c4e6a6f0c15464e157b4db7638a,732
4d6af158889147d8cc51315b59831197,732
791311892ce625d16d32786c2679cb88,732
3801cae9487269643906f2125d89d754,464
4153266b2a167958f6ef872b8a13317f,732
be7ed1c27780067717d28964044acf51,732
2773263bb3ff90f9890cd4ac6adb0cca,464
3e127d066d153ab419d86c593f77d629,732
f6eca453d638d5014603cedd9b85c5bc,464
a39fbf09023d2b98cbd486ec3a244765,464
d929573c99d7f45dd0c3f939aaf7dd51,732
d4217a56e6a55ae05fc30ae95189f71c,464
639d6384a2c426f01597d1a668d571a7,732
0b89974eac5087159b029dc61980510a,732
c357ca60285c4f965a156c54d15be756,732
0615e7f6801286210ba978da7a84c3e6,732
27ddf29f30544ee759fcb51ee558c09d,732
dbe9c4f1287fb16ff4658aff9c318d5e,732
28375cb44f99643a7d8898b3d6efa20f,464
383b76214a1bbc1cc8c602c63e479fe1,732
784605d22d28215f13a57e84627fd9a2,732
5414fa19cb93ac5c913b441b1df8fdc0,464
f4031c2fc6342ef8b328538d26782e0b,732
1d46afe83c6d66741ec950843307f6e6,732
46f7fd4c992bc2162b87b9ccc08c777b,732
2c47c51d1538b82eb31a2f6a66e4b340,732
a59dd8f627b26d7347a40dd2bf45b8ff,732
a3d9980ac0e9517507ffedb37779895a,732
17680681fea1cf6df15762035ff09bb8,732
75f25b0878277c2835885f881f0479f8,464
030c7d18b20ee586db3b74d9966c0348,601
b50e2e902b001cb003bc970189432426,732
964581a80041d2f57c4dd40a82ad94dd,732
e1815436e1aa4c04fb4d853df0a22d17,732
fee2e52c250a812d0e299eb8d0ce558d,464
7fa62c3810e0689e3661bd381c944beb,732
3d6866a225fc3b20eea604335c7fc28f,732
07f59eff2e615d4c37658c214cf77996,732
59e088fbdd3688d4f8adf05eed2d1d62,732
a0c215cf0e2fcbc8e5d9550bfa1e7882,464
d97a794bc6e951b13891873045115174,732
2808c7a907535b23d35c14369b12ca84,732
8c7757543b9a3245b4fa95b789392caf,732
28378d3b2ebdfd18b784559c2334a5c0,732
15d6c5d42688cbc390e9ba241e93b941,732
fc2410779646401f73d8d690f6e48f6e,732
0ecc886c88bf3845dce95f2281153b22,732
16f3532d0c649270ba1b6ee6a2a991d1,732
fef53a1dada4a77de35c609180d41936,732
502e97f2577d5f29e6b86752400fb0c4,464
9ecd953bcb9cdb6baa452aeb374b70fc,732
11d2c1b5a1752c174e66dd49390f36b3,464
d2ad2845327eaa0a6c14736820256086,677
20e812366b1c572222f1fa1e3d54dc54,732
501505f4ad95c828a271445f5073a91d,152
d48d48b4cd9b73ab22fe5803b0b8c89d,732
271bf8c2fba59761e340679b3bd8c0eb,732
c530c6986170aa1aefe7a930a56ad0db,732
61e61ec16868b8972f02fb6fcf4c6ce7,732
08edd1314726785f6feddcce7854f881,732
ced6cfcd03794991fa5145f7f03675fa,732
c05f7d929cc67ef267e0ffda404ad0f5,464
49a6cac0897d9cf6459de6e69cc1edbb,732
f64eac6ce9235a3b9d2c8a6a8a14ec65,732
05c985774004cd0e789e33f2a00ca26a,732
1e2903be123e2e0b747943f46d31113d,732
3e353362a5220111748db43b03ef7551,732
06a0cec19b33162bb0f24416107540fc,732
96661ef2172a349dc017b771e01d141e,853
b9e87230db892717fdc5a0513e312ccb,464
4ba2d967c5b3f5350ae268556392dfba,732
bd278c914f53755282f1d05873c180f3,732
439c8e6adb72aebff8ddff6700d90730,732
371e69a08d83234cc16e353734885d26,732
4507ae5207b459e40a261f5a96e29243,732
6ff9b514f288e9907b136ba36854a1eb,732
93f36cd6408982bf02078577ec224014,732
a654571d633f91a8b451ccf979395a19,601
ca0b3b022555260061836d1080e1bad5,732
d9767b49542a15076d1f6971a03df338,732
99a8b2b93391f72f4437c4bf4465501e,464
fe95bce0791a7015500d4b9f1d3d32c9,732
c90c3e687bd51f10c36507f2c0ded63b,732
ac372cb67bbd28df50944e4881630142,732
51ddc777d64367bbc67e0dbe56621eee,732
365ae0d5dbd27236a807141c5beba78c,732
bb6d74478c40198ecc1006daf3d895a3,732
ac9734b702267d0b1016ae7d41d62928,732
14dfa660b37a9ee2712c38f9002d8980,732
04c2ed055c16441bc123f341ff172128,732
a67d23faf4814a052c423db9b2f28bee,732
3cff6b88d93b15c1118ddda2892339c6,732
506121a04700de37d9484b8902b14224,732
8ede0bc5a4976385dcfe6e38feaf90c2,732
98e0764fa15ffea4277ef27c3bd9e581,732
de220ee3f8f13956629ebb512391976a,732
5a01435acf089e5dfe97eb7865c67b2e,732
f067618d20c64929543b7a7570f8e629,228
f8a950b59250dbb8b189a07ad70d85ea,732
6357498ff675b57ed4d100d83a2c1469,601
872aeb779216b09b04eb15dba20afe3e,732
9de9a598bc6e0248ac4337b212fac452,732
084479b162adf58c77c4fa906d3f900a,732
f5b06a47e3ec141ecc6590a543274f68,732
bba3d48d94128d77b9f8a008d383296e,732
9cc76e9c506161a38e224ae7b4ef4d97,732
54fcf8d8ca6a7b6cec5c200f951598f9,732
67a01e7f879b2427935f0b5d3b0d16a7,732
654919591aa6028d82cf21c011de2e5f,732
2e54c9bac859bc91b0c181c0bacbea92,732
ed87bec047ced0823db1c3d4065ba1f0,464
8939770ea847cce7a6278c5467dc3d87,732
f9efa9e2a3226e4c2735542efc63a868,732
2bad27d8efb4f03863c00c7f573716f0,464
d8609b1d608b22c597505364414fb917,732
dbf106cd7622cc0415fd4a0c3131f09d,732
045ed95be146d994cfe64be27e1c936a,732
f76d885e48357b99382078727776ee84,732
864841d2f9cda02feeaf03acf29407c6,732
b00026ae79cccfff87ea5923a5f2e76c,732
8367922ad8b74c6047ea82f4d527ce04,732
85d53b3b764e317c7faacf3221ccc80c,732
9b81acdecd60aee4738f9e2fce9d1d37,732
234e89833f23f32bed44a3b314cbf786,732
e160abb56dc630f27dc5e1d3f41062ce,732
8c94b5b5867e8cc67d36629be169f993,429
423df250254dc327aca81e1903555ec3,732
eeb391e30d46f5f2cfe4108c7a251ee9,732
9d4bc0dc9daee3a8d0baecf4d2365c4f,429
3dadf8d0037d2a1f40999c9da306b03a,732
374c619f727583cb75563891f6b855ee,464
e13d37bfdad34e200755cffa193366e8,464
37f77452e94321c7be2beeb84d381316,732
09eb123fe843cf1ae1c14be61f55be37,464
a795a2f7d04f9959a3ea098c5d1fbcb9,732
97b9e4f0054330bf0f33e56a80f3b5a7,853
f32502f507fa358e2129585b6b21bb60,464
de9b0e94e1a74daf9062d84a69fdbba5,732
ede49069fad0d28a8cb11d9653cecc14,732
61f6255e139b2091d32fd21e20ddaa36,464
efe9c77b5b7b7bebbdb9ae8daf7cc211,732
ae0fba8779fb181a0eb4efc7911e6984,732
746e9072f9d600f848ad9983de373804,732
a131752592bf0ff25acd37c22e8dc40b,732
b2b184e133c5890d48af038f3af513ed,732
e1aafe2dea8f46187d576ee069434b5e,732
f3ffaa63cce4b75f414d93f65bd45743,732
0a4a063484eba8522de89bdb24878e74,732
64a7a824d6d5c6dba0d881c4505e4240,464
10ad6de262a7bd2aa52abf3f286bd175,464
b40be7f30a4a196d5fad13d01a4f51b8,732
21c9ee5b4cfa9ad3e072b8f4d14812b2,732
f6a544074a9b83ccd98bf65a2c3eb57c,732
c2fa2fd261cbb25a458e16a7e5be6bf9,732
5e0890d770f76292620c958c713ba86a,732
14938f3583bb58e008073772deb9832d,732
51972b83934d272b99a9d14fb1febc08,464
046356594366559d408353df3711de5e,732
fb3dac8dd57973515860e1ee184f5f0a,732
f7a452821f33c8cd9152fb659ad68213,732
4091b786289dd16152be4a0e8f455294,732
ba03abd3b6c6c044eb944730ed271e8b,732
b89af3dc918af450fbc1c5a4924d2e96,732
86429297db040c7ce0891aaa774c8b3d,732
\" target=\"_blank\">experiment/kaggle.csv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args_outfile = os.path.join(args_experiment, 'kaggle.csv')\n",
    "# args_model = get_model(args_experiment)\n",
    "\n",
    "# state_dict = torch.load(args_model)\n",
    "# model = Net()\n",
    "# model.load_state_dict(state_dict)\n",
    "# model.eval()\n",
    "# if use_cuda:\n",
    "#     model.cuda()\n",
    "\n",
    "test_dir = args_data + '/test_images/mistery_category'\n",
    "\n",
    "\n",
    "output_file = open(args_outfile, \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "for f in tqdm(os.listdir(test_dir)):\n",
    "    if 'jpg' in f:\n",
    "        data = transform_test(pil_loader(test_dir + '/' + f))\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "#         if use_cuda:\n",
    "#             data = data.cuda()\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "print(\"Succesfully wrote \" + args_outfile + ', you can upload this file to the kaggle competition website')\n",
    "\n",
    "# Check if output_file is available\n",
    "print('kaggle.csv' in os.listdir('./experiment/'))\n",
    "print(os.listdir('experiment'))\n",
    "\n",
    "# create a link to download the dataframe\n",
    "create_download_link('experiment/kaggle.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6491ac8c8c8bcc42a617e2c72e608cd4bcaf5eb"
   },
   "outputs": [],
   "source": [
    "data = Variable (torch.rand(2,3,299,299))\n",
    "outs = model(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
