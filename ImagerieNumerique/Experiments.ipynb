{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook offers some experiments on the paper:\n",
    "\n",
    "\n",
    "\"Globally and Locally Consistent Image Completion\", SATOSHI IIZUKA, EDGAR SIMO-SERRA,\n",
    "HIROSHI ISHIKAWA\n",
    "\n",
    "The employed code comes from https://github.com/akmtn/pytorch-siggraph2017-inpainting\n",
    "\n",
    "It requires a PyTorch version below 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models import _NetCompletion, _NetContext, completionnet_places2\n",
    "from src.ablation import completionnet_ablation, copy_weights\n",
    "from src.masking import run_draw\n",
    "from src.inpaint import inpainting, inpainting2, load_network, random_mask\n",
    "from src.inpaint import load_mask, load_data, post_processing\n",
    "from src.train import load_dataset, train_random_mask, train_discriminator, get_networks\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.modules.loss import BCELoss, MSELoss\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "model, datamean = load_network()\n",
    "filename = \"completionnet_places2.t7\"\n",
    "url = \"http://hi.cs.waseda.ac.jp/~iizuka/data/completionnet_places2.t7\"\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    urllib.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple tests on an image\n",
    "Code from https://stackoverflow.com/a/36382158/4986615\n",
    "\n",
    "Press ESC to quit the windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/bridge.jpg\")\n",
    "run_draw(img, \"mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "mask = cv2.imread(\"mask.png\")\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.title(\"Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = load_mask(\"mask.png\", output_shape=(600, 400))\n",
    "I = load_data(\"images/bridge.jpg\", output_shape=(600, 400))\n",
    "out = inpainting(model, datamean, I, M, postproc=True)\n",
    "vutils.save_image(out, 'out.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "out_im = cv2.imread(\"out.png\")[:,:,::-1] \n",
    "plt.imshow(out_im)\n",
    "plt.axis('off')\n",
    "plt.title(\"Output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Computation of the loss function on a set of random masks\n",
    "Here we want to draw a metric for the quality of the reconstruction.\n",
    "We use a sum of a weighted MSE and a binary cross entropy as in the reference paper for training the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wtl2 = 0.5\n",
    "bce_loss = BCELoss()\n",
    "mse_loss = MSELoss()\n",
    "        \n",
    "M = random_mask(output_shape=(600, 400))\n",
    "I = load_data(\"images/bridge.jpg\", output_shape=(600, 400))\n",
    "out = inpainting(model, datamean, I, M, postproc=False)\n",
    "out2 = out.float()      \n",
    "\n",
    "error = wtl2*mse_loss(out2, I) + (1 - wtl2)*bce_loss(out2, I)\n",
    "print(\"Normal:\", error)\n",
    "\n",
    "out_proc = post_processing(I, M, out)\n",
    "out_proc2 = out_proc.float()      \n",
    "error = wtl2*mse_loss(out_proc2, I) + (1 - wtl2)*bce_loss(out_proc2, I)\n",
    "print(\"Post-processing:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Neural networks\n",
    "\n",
    "The local and global discriminators were not open-sourced. They are implemented in `models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = _NetCompletion()\n",
    "summary(completion, input_size=(4, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import _NetContext\n",
    "context = _NetContext()\n",
    "summary(context, [(3, 128, 128), (3, 256, 256)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "\n",
    "## 4.1. Visualize mask and patch\n",
    "(Violet = global, green = local, yellow = hole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import train_random_mask\n",
    "mask, patch = train_random_mask(2)\n",
    "m, p = mask[0,0], patch[0]\n",
    "m[p[0]:p[2], p[1]:p[3]] += 1\n",
    "plt.imshow(m.numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Training the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, context = get_networks(cuda=False)\n",
    "model, datamean = load_network()\n",
    "dataloader = load_dataset(dataset=\"cifar10\", dataroot=\"dataset/cifar10\", batch_size=2)\n",
    "train_discriminator(model, context, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Removing neurons in the pre-trained model\n",
    "Kind of an ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "A = completionnet_places2\n",
    "A.load_state_dict(torch.load('completionnet_places2.pth'))\n",
    "B = completionnet_ablation(dropout)\n",
    "copy_weights(A, B)\n",
    "\n",
    "# activate dropout during eval\n",
    "B.eval()\n",
    "for m in B.modules():\n",
    "    if m.__class__.__name__.startswith('Dropout'):\n",
    "        m.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
