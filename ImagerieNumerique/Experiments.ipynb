{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook offers some experiments on the paper:\n",
    "\n",
    "\n",
    "\"Globally and Locally Consistent Image Completion\", SATOSHI IIZUKA, EDGAR SIMO-SERRA,\n",
    "HIROSHI ISHIKAWA\n",
    "\n",
    "The employed code comes from https://github.com/akmtn/pytorch-siggraph2017-inpainting\n",
    "\n",
    "It requires a PyTorch version below 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.models import _NetCompletion, _NetContext, completionnet_places2\n",
    "from src.ablation import completionnet_ablation, copy_weights\n",
    "from src.masking import run_draw\n",
    "from src.inpaint import inpainting, inpainting2, load_network, random_mask\n",
    "from src.inpaint import load_mask, load_data, post_processing\n",
    "from src.train import load_dataset, train_random_mask, train_discriminator, get_networks\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn.modules.loss import BCELoss, MSELoss\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "from moviepy.editor import *\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "\n",
    "filename = \"completionnet_places2.t7\"\n",
    "url = \"http://hi.cs.waseda.ac.jp/~iizuka/data/completionnet_places2.t7\"\n",
    "\n",
    "if not os.path.isfile(filename):\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "model, datamean = load_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simple tests on an image\n",
    "Code from https://stackoverflow.com/a/36382158/4986615\n",
    "\n",
    "Press ESC to quit the windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"images/bridge.jpg\")\n",
    "run_draw( img, \"mask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "mask = cv2.imread(\"mask.png\")\n",
    "plt.imshow(mask)\n",
    "plt.axis('off')\n",
    "plt.title(\"Mask\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M = load_mask(\"mask.png\", output_shape=(600, 400))\n",
    "I = load_data(\"images/flower.jpg\", output_shape=(600, 400))\n",
    "out = inpainting(model, datamean, I, M, postproc=False, skip=False)\n",
    "vutils.save_image(out, 'out.png', normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "out_im = cv2.imread(\"out.png\")[:,:,::-1] \n",
    "plt.imshow(out_im)\n",
    "plt.axis('off')\n",
    "plt.title(\"Output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Computing on a short video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Next lines are for downloading the required video from Youtube\n",
    "if not os.path.exists(\"wwf_forest.mp4\"):\n",
    "    os.system(\"youtube-dl gpzuVt_mkKs -o wwf_forest.mp4\")\n",
    "\n",
    "clip = VideoFileClip(\"wwf_forest.mp4\").subclip((0,6.0),(0,6.2))\n",
    "w, h = 600, 400\n",
    "clip = clip.resize( (w, h) )\n",
    "clip.ipython_display(fps=20, loop=True, autoplay=True)\n",
    "M = torch.FloatTensor(1, h, w).fill_(0.)\n",
    "mask_w, mask_h = np.random.randint(60,100, 2)\n",
    "px = np.random.randint(0, w-mask_w)\n",
    "py = np.random.randint(0, h-mask_h)\n",
    "M[:, py:py+mask_h, px:px+mask_w] = 1.\n",
    "\n",
    "\n",
    "def inpainting_video(clip, model, datamean, M):\n",
    "    \n",
    "    def fl(gf,t):\n",
    "        im = gf(t)\n",
    "        h,w,d = im.shape\n",
    "        im = im.transpose((2,0,1)).astype(np.float64)\n",
    "        I = torch.from_numpy(im/255.).float()\n",
    "        out = inpainting(model, datamean, I, M, postproc=False, skip=False).data.numpy()\n",
    "        out = (out*255.).transpose((1,2,0)).astype(int)\n",
    "        return out\n",
    "    \n",
    "    return clip.fl(fl)\n",
    "\n",
    "clip_inpainted = clip.fx(inpainting_video, model, datamean, M)\n",
    "# clip_inpainted.ipython_display(fps=20, loop=True, autoplay=True)\n",
    "clip_inpainted.write_videofile('inpainted_forest.mp4', bitrate=\"3000k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoFileClip(\"wwf_forest.mp4\").save_frame(\"wood.jpg\", t=26.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Computation of the loss function on a set of random masks\n",
    "Here we want to draw a metric for the quality of the reconstruction.\n",
    "We use a sum of a weighted MSE and a binary cross entropy as in the reference paper for training the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wtl2 = 0.5\n",
    "bce_loss = BCELoss()\n",
    "mse_loss = MSELoss()\n",
    "        \n",
    "M = random_mask(output_shape=(600, 400))\n",
    "I = load_data(\"images/bridge.jpg\", output_shape=(600, 400))\n",
    "out = inpainting(model, datamean, I, M, postproc=False)\n",
    "out2 = out.float()      \n",
    "\n",
    "error = wtl2*mse_loss(out2, I) + (1 - wtl2)*bce_loss(out2, I)\n",
    "print(\"Normal:\", error)\n",
    "\n",
    "out_proc = post_processing(I, M, out)\n",
    "out_proc2 = out_proc.float()      \n",
    "error = wtl2*mse_loss(out_proc2, I) + (1 - wtl2)*bce_loss(out_proc2, I)\n",
    "print(\"Post-processing:\", error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of the hole size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [20,30,50,80,130,210]\n",
    "N = len(size)\n",
    "w, h = 600, 400\n",
    "masks = torch.FloatTensor(N, h, w).fill_(0.)\n",
    "px = np.random.randint(110, 490)\n",
    "py = np.random.randint(110, 290)\n",
    "image = \"forest\"\n",
    "I = load_data(f\"images/{image}.jpg\", output_shape=(w, h))\n",
    "\n",
    "for i in range(N):\n",
    "    half = int(size[i]/2)\n",
    "    res_dir = os.path.join(\"results\", \"hole\", image)\n",
    "    os.makedirs(res_dir, exist_ok=True)\n",
    "    masks[i, py-half:py+half, px-half:px+half] = 1.\n",
    "    out = inpainting(model, datamean, I, masks[i:i+1], postproc=False)\n",
    "    out = out.data.numpy()\n",
    "    out = out.transpose((1,2,0))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(out)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(res_dir, f'hole-{i}.png'), bbox_inches='tight')\n",
    "    \n",
    "    out = inpainting(model, datamean, I, masks[i:i+1], postproc=False, skip=True)\n",
    "    out = out.data.numpy()\n",
    "    out = out.transpose((1,2,0))\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.imshow(out)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(os.path.join(res_dir, f'hole-sanity-{i}.png'), bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influence of local context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "The local and global discriminators were not open-sourced. They are implemented in `models.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = _NetCompletion()\n",
    "summary(completion, input_size=(4, 512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import _NetContext\n",
    "context = _NetContext()\n",
    "summary(context, [(3, 128, 128), (3, 256, 256)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training\n",
    "\n",
    "## 4.1. Visualize mask and patch\n",
    "(Violet = global, green = local, yellow = hole)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.train import train_random_mask\n",
    "mask, patch = train_random_mask(2)\n",
    "m, p = mask[0,0], patch[0]\n",
    "m[p[0]:p[2], p[1]:p[3]] += 1\n",
    "plt.imshow(m.numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Training the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, context = get_networks(cuda=False)\n",
    "model, datamean = load_network()\n",
    "dataloader = load_dataset(dataset=\"cifar10\", dataroot=\"dataset/cifar10\", batch_size=2)\n",
    "train_discriminator(model, context, dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Removing neurons in the pre-trained model\n",
    "Kind of an ablation study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout = 0.1\n",
    "A = completionnet_places2\n",
    "A.load_state_dict(torch.load('completionnet_places2.pth'))\n",
    "B = completionnet_ablation(dropout)\n",
    "copy_weights(A, B)\n",
    "\n",
    "# activate dropout during eval\n",
    "B.eval()\n",
    "for m in B.modules():\n",
    "    if m.__class__.__name__.startswith('Dropout'):\n",
    "        m.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
