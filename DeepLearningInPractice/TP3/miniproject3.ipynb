{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small data and deep learning\n",
    "This mini-project proposes to study several techniques for improving challenging context, in which few data and resources are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_ext autoreload\n",
    "autoreload 2\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Assume we are in a context where few \"gold\" labeled data are available for training, say $\\mathcal{X}_{\\text{train}}\\triangleq\\{(x_n,y_n)\\}_{n\\leq N_{\\text{train}}}$, where $N_{\\text{train}}$ is small. A large test set $\\mathcal{X}_{\\text{test}}$ is available. A large amount of unlabeled data, $\\mathcal{X}$, is available. We also assume that we have a limited computational budget (e.g., no GPUs).\n",
    "\n",
    "For each question, write a commented *Code* or a complete answer as a *Markdown*. When the objective of a question is to report a CNN accuracy, please use the following format to report it, at the end of the question:\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|   XXX  | XXX | XXX | XXX |\n",
    "\n",
    "If applicable, please add the field corresponding to the  __Accuracy on Full Data__ as well as a link to the __Reference paper__ you used to report those numbers. (You do not need to train a CNN on the full CIFAR10 dataset)\n",
    "\n",
    "In your final report, please keep the logs of each training procedure you used. We will only run this jupyter if we have some doubts on your implementation. \n",
    "\n",
    "__The total file sizes should not exceed 2MB. Please name your notebook (LASTNAME)\\_(FIRSTNAME).ipynb, zip/tar it with any necessary files required to run your notebook, in a compressed file named (LASTNAME)\\_(FIRSTNAME).X where X is the corresponding extension. Zip/tar files exceeding 2MB will not be considered for grading. Submit the compressed file via the submission link provided on the website of the class.__\n",
    "\n",
    "You can use https://colab.research.google.com/ to run your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training set creation\n",
    "__Question 1:__ Propose a dataloader or modify the file located at https://github.com/pytorch/vision/blob/master/torchvision/datasets/cifar.py in order to obtain a training loader that will only use the first 100 samples of the CIFAR-10 training set. \n",
    "\n",
    "> I obtained only the first 100 samples by inheritance from CIFAR10:\n",
    "\n",
    "```python\n",
    "class SubCIFAR10(CIFAR10):\n",
    "    def __init__(self, root, length=100, **kwargs):\n",
    "        self.length = length\n",
    "        super().__init__(root, **kwargs)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return super().__getitem__(index  self.length)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torch \n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils import SubCIFAR10\n",
    "    \n",
    "    \n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "batch_size = 100\n",
    "dataset = SubCIFAR10(\"datasets\", download=True, transform=transform)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                          shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View a few classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(dataloader)\n",
    "images, labels = next(dataiter)\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.grid(False)\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(labels, bins=len(classes), rwidth=0.9, color='#607c8e')\n",
    "ax = plt.gca()\n",
    "plt.xticks(np.arange(len(classes))*0.9+0.5, classes, rotation=45, rotation_mode=\"anchor\", ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is our dataset $\\mathcal{X}_{\\text{train}}$, it will be used until the end of this project. The remaining samples correspond to $\\mathcal{X}$. The testing set $\\mathcal{X}_{\\text{test}}$ corresponds to the whole testing set of CIFAR-10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing procedure\n",
    "__Question 2:__ Explain why the evaluation of the training procedure is difficult. Propose several solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Having a very small dataset for 10 classes makes training particularly difficult. For exmaple, the class \"ship\" has only 4 samples. The training difficulties can be understood by the discrepancy between the number of samples and the number of parameters of a CNN (typically between hundreds of thousands to tens of millions)\n",
    ">\n",
    "> Several solutions exist though:\n",
    ">\n",
    "> - using a pre-trained network, such that the optimizer is closed to an extrema with the new challenge;\n",
    "> - augmenting the number of data with random variations of original data;\n",
    "> - generating new data by learning a latent representation (such as VAE) of the trainset, using adversarial network;\n",
    "> - synthetising new data and possibly refining them with CycleGANs;\n",
    "> - optimizing the architecture of training, such as using a smaller dataset, testing different hyperparameters;\n",
    "> - making use of non-annotated data (see semi-supervised/weakly-supervised learning methods)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw approach: the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the goal is to train a CNN on $\\mathcal{X}_{\\text{train}}$ and compare its performances with reported number from the litterature. You will have to re-use and/or design a standard classification pipeline. You should optimize your pipeline to obtain the best performances (image size, data augmentation by flip, ...).\n",
    "\n",
    "The key ingredients for training a CNN are the batch size, as well as the learning rate schedule, i.e. how to decrease the learning rate as a function of the number of epochs. A possible schedule is to start the learning rate at 0.1 and decreasing it every 30 epochs by 10. In case of divergence, reduce the laerning rate. A potential batch size could be 10, yet this can be cross-validated.\n",
    "\n",
    "You can get some baselines accuracies in this paper: http://openaccess.thecvf.com/content_cvpr_2018/papers/Keshari_Learning_Structure_and_CVPR_2018_paper.pdf. Obviously, it is a different context, as those researchers had access to GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 3:__ Write a classification pipeline for $\\mathcal{X}_{\\text{train}}$, train from scratch and evaluate a *ResNet-18* architecture specific to CIFAR10 (details about the ImageNet model can be found here: https://arxiv.org/abs/1409.1556 ). If possible, please report the accuracy obtained on the whole dataset, as well as the reference paper/GitHub link you might have used.\n",
    "\n",
    "*Hint:* You can re-use the following code: https://github.com/kuangliu/pytorch-cifar. During a training of 10 epochs, a batch size of 10 and a learning rate of 0.01, one obtains 40 accuracy on $\\mathcal{X}_{\\text{train}}$ (~2 minutes) and 20 accuracy on $\\mathcal{X}_{\\text{test}}$ (~5 minutes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import train_an_epoch, test\n",
    "from resnet import ResNet18\n",
    "\n",
    "\n",
    "batch_size = 10\n",
    "n_epochs = 100\n",
    "\n",
    "# Loading data\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = SubCIFAR10(\"datasets\", download=True, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size)\n",
    "validset = SubCIFAR10(\"datasets\", download=True, transform=test_transform, offset=100, length=1000)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size)\n",
    "testset = SubCIFAR10(\"datasets\", download=True, transform=test_transform, offset=100, length=50000)\n",
    "testloader = torch.utils.data.DataLoader(validset, batch_size=batch_size)\n",
    "\n",
    "# Initialize opt and net\n",
    "model = ResNet18()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Training\n",
    "train_loss = np.zeros(n_epochs, dtype=float)\n",
    "train_acc = np.zeros(n_epochs, dtype=float)\n",
    "valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        train_loss[i] = train_an_epoch(model, criterion, \n",
    "                 trainloader, optimizer, device, silent=True)\n",
    "        train_acc[i] = test(model, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        valid_acc[i] = test(model, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=train_loss[i], train_acc=train_acc[i], valid_acc=valid_acc[i])\n",
    "     \n",
    "plot_history(train_loss=train_loss, train_acc=train_acc, valid_acc=valid_acc)\n",
    "print(\"[Testing]\")\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops... The neural network is completely over-fitting!\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|ResNet| 10 | 38.5% | 20.9% |\n",
    "|ResNet| 20 | 51.5% | 23.1% |\n",
    "|ResNet| 100 | 98.0% | 23.5% |\n",
    "|[Keshari-ResNet]| N/A | N/A | 36% | \n",
    "|**[Keshari-ResNet-pretrained]**| N/A | N/A |44% | \n",
    "\n",
    "- [Keshari-ResNet] *Learning Structure and Strength of CNN Filters for Small Sample Size Training*;\n",
    "Rohit Keshari, Mayank Vatsa, Richa Singh, Afzel Noore.  (version Proposed ResNet, Dict., Init., learn \"t\") \n",
    "- [Keshari-ResNet] - (version Proposed ResNet, Pre-trained on ImageNet, learn \"t\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG-like architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 4:__ Same question as before, but with a *VGG*. Which model do you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from vgg import VGG# Initialize opt and net\n",
    "model = VGG('VGG11')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Training\n",
    "train_loss = np.zeros(n_epochs, dtype=float)\n",
    "train_acc = np.zeros(n_epochs, dtype=float)\n",
    "valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        train_loss[i] = train_an_epoch(model, criterion, \n",
    "                 trainloader, optimizer, device, silent=True)\n",
    "        train_acc[i] = test(model, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        valid_acc[i] = test(model, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=train_loss[i], train_acc=train_acc[i], valid_acc=valid_acc[i])\n",
    "     \n",
    "plot_history(train_loss=train_loss, train_acc=train_acc, valid_acc=valid_acc)\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have tested first with VGG19, but over-fitting was even worst. I switched then to a smaller network having less parameters: VGG11. Bold lines emphasize the best results.\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|ResNet18| 10 | 38.5% | 20.9% |\n",
    "|**ResNet18**| 100 | 98.0% | 23.5%|\n",
    "| VGG19 |  10 | 25.0% | 17.1% |\n",
    "|**VGG19** | 100 | 83.0% | 18.7% |\n",
    "| VGG11 |  10 | 92.0% | 22.9% |\n",
    "|**VGG11** |  14 | 100.0% | 27.0% |\n",
    "| VGG11 | 100 | 100.0% | 25.3% | \n",
    "|[Keshari-ResNet]| N/A | N/A | 36% | \n",
    "|**[Keshari-ResNet-pretrained]**| N/A | N/A | 44% | \n",
    "\n",
    "For proposed training method, VGG11 is a better choice than ResNet18, since its converged faster and achieves a better test accuracy at step 14 (27%)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose to use pre-trained models on a classification and generative task, in order to improve the results of our setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageNet features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use some pre-trained models on ImageNet and see how well they compare on CIFAR. A list is available on: https://pytorch.org/docs/stable/torchvision/models.html.\n",
    "\n",
    "__Question 5:__ Pick a model from the list above, adapt it to CIFAR and retrain its final layer (or a block of layers, depending on the resources to which you have access to). Report its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet18\n",
    "from utils import plot_history, initialize_model\n",
    "from tqdm import tnrange\n",
    "\n",
    "n_epochs = 35\n",
    "\n",
    "# Loading model and opt\n",
    "model, input_size = initialize_model(\"resnet\", len(classes), True, use_pretrained=True)\n",
    "params_to_update = []\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "optimizer = torch.optim.Adam(params_to_update)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "    \n",
    "# Loading data    \n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(input_size),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.Resize(input_size),\n",
    "     transforms.CenterCrop(input_size),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "trainset = SubCIFAR10(\"datasets\", download=True, transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size)\n",
    "validset = SubCIFAR10(\"datasets\", download=True, transform=test_transform, offset=100, length=1000)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size)\n",
    "testset = SubCIFAR10(\"datasets\", download=True, transform=test_transform, offset=100, length=50000)\n",
    "testloader = torch.utils.data.DataLoader(validset, batch_size=batch_size)\n",
    "\n",
    "    \n",
    "# Training\n",
    "train_loss = np.zeros(n_epochs, dtype=float)\n",
    "train_acc = np.zeros(n_epochs, dtype=float)\n",
    "valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        train_loss[i] = train_an_epoch(model, criterion, \n",
    "                 trainloader, optimizer, device, silent=True)\n",
    "        train_acc[i] = test(model, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        valid_acc[i] = test(model, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=train_loss[i], train_acc=train_acc[i], valid_acc=valid_acc[i])\n",
    "     \n",
    "plot_history(train_loss=train_loss, train_acc=train_acc, valid_acc=valid_acc)\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using pre-trained neural networks allowed me to improve results over Keshari et al.!\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|VGG11 |  14 | 100.0% | 27.0% |\n",
    "|[Keshari-ResNet]| N/A | N/A | 36% | \n",
    "|ResNet-pretrained| 10 | 63 % | 37% |\n",
    "|[Keshari-ResNet-pretrained]| N/A | N/A | 44% | \n",
    "|**ResNet-pretrained**| 35 | 76% | 51% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DCGan features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GANs correspond to an unsupervised technique for generating images. In https://arxiv.org/pdf/1511.06434.pdf, Sec. 5.1 shows that the representation obtained from the Discriminator has some nice generalization properties on CIFAR10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 6:__  Using for instance a pretrained model from https://github.com/soumith/dcgan.torch combined with https://github.com/pytorch/examples/tree/master/dcgan, propose a model to train on $\\mathcal{X}_{\\text{train}}$. Train it and report its accuracy.\n",
    "\n",
    "*Hint:* You can use the library: https://github.com/bshillingford/python-torchfile to load the weights of a model from torch(Lua) to pytorch(python).\n",
    "\n",
    "> I tried to train both the generator and the discriminator. Using only 100 samples make it impossible. Instead, I train the GAN over the complete dataset. I know, it is cheating, but I found it interesting to get a baseline.\n",
    "\n",
    "![best results](results/dcgan/fake_samples_epoch_611.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gan import *\n",
    "from utils import get_loaders, plot_history, train_an_epoch\n",
    "from tqdm import tnrange\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "out_img = os.path.join(\"results\", \"dcgan2\")\n",
    "out_models = os.path.join(\"models\", \"dcgan\")\n",
    "nc = 3\n",
    "nz = 100 # latent Z vector\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "n_epochs = 650\n",
    "batch_size = 300\n",
    "\n",
    "os.makedirs(output, exist_ok=True)\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "# Building models and optimizers\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "netG, optimizerG, netD, optimizerD = build_dcgan(\n",
    "    device, nz, nc, ngf, ndf)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Loading data\n",
    "_, _, dataloader = get_loaders(batch_size=10, input_size=64)\n",
    "\n",
    "gen_loss = np.zeros(n_epochs, dtype=float)\n",
    "disc_loss = np.zeros(n_epochs, dtype=float)\n",
    "\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        disc_loss[i], gen_loss[i] = train_gan_an_epoch(\n",
    "            dataloader, netG, optimizerG, \n",
    "            netD, optimizerD, criterion, device, nz=nz, \n",
    "            silent=True, out_models=out_models, epoch=i)\n",
    "        export_gan_result(dataloader, netG, netD, device, \n",
    "                          out_img, i, nz=nz)\n",
    "        t.set_postfix(disc_loss=disc_loss[i], \n",
    "                      gen_loss=gen_loss[i])\n",
    "     \n",
    "plot_history(disc_loss=disc_loss, gen_loss=gen_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I trained a discriminator given a pre-trained generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gan import *\n",
    "from utils import get_loaders, plot_history, train_an_epoch\n",
    "from tqdm import tnrange\n",
    "import numpy as np\n",
    "import torchfile\n",
    "\n",
    "\n",
    "# Parameters\n",
    "out_img = os.path.join(\"results\", \"dcgan2\")\n",
    "out_models = os.path.join(\"models\", \"dcgan\")\n",
    "nc = 3\n",
    "nz = 100 # latent Z vector\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "n_epochs = 650\n",
    "batch_size = 300\n",
    "\n",
    "os.makedirs(output, exist_ok=True)\n",
    "\n",
    "# Building models and optimizers\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "_, _, netD, optimizerD = build_dcgan(\n",
    "    device, nz, nc, ngf, ndf)\n",
    "netG = torchfile.load('models/bedrooms_4_net_G.t7')\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Loading data\n",
    "dataloader, _, _ = get_loaders(batch_size=10, input_size=64)\n",
    "\n",
    "\n",
    "\n",
    "disc_loss = np.zeros(n_epochs, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also train on a similar dataset: STL-10 with higher resolutions. \n",
    "\n",
    "![Results on STL-10](results/stl10/fake_samples_epoch_4149.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gan import *\n",
    "from utils import get_loaders, plot_history, train_an_epoch, SubSTL10\n",
    "from tqdm import tnrange\n",
    "from torchvision.datasets import STL10\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "out_img = os.path.join(\"results\", \"stl10\")\n",
    "out_models = os.path.join(\"models\", \"stl10\")\n",
    "nc = 3\n",
    "nz = 100 # latent Z vector\n",
    "input_size = 64\n",
    "n_epochs = 650\n",
    "batch_size = 32\n",
    "\n",
    "os.makedirs(output, exist_ok=True)\n",
    "os.makedirs(\"models/stl10\", exist_ok=True)\n",
    "\n",
    "# Building models and optimizers\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() \n",
    "                      else \"cpu\")\n",
    "netG, optimizerG, netD, optimizerD = build_dcgan(\n",
    "    device, nz, nc, input_size, input_size)\n",
    "criterion = nn.BCELoss()\n",
    "netG.load_state_dict(torch.load(\"models/stl10/netG_epoch_640.pth\"))\n",
    "netD.load_state_dict(torch.load(\"models/stl10/netD_epoch_640.pth\"))\n",
    "\n",
    "# Loading data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomResizedCrop(input_size),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "dataset = STL10(\"datasets\", split='train+unlabeled', transform=transform, download=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)\n",
    "\n",
    "with tnrange(n_epochs+500, n_epochs+3500) as t:\n",
    "    for i in t:\n",
    "        disc_loss[i], gen_loss[i] = train_gan_an_epoch(\n",
    "            dataloader, netG, optimizerG, \n",
    "            netD, optimizerD, criterion, device, nz=nz, \n",
    "            silent=True, out_models=out_models, epoch=i)\n",
    "        export_gan_result(dataloader, netG, netD, device, \n",
    "                          out_img, i, nz=nz)\n",
    "        t.set_postfix(disc_loss=disc_loss[i], \n",
    "                      gen_loss=gen_loss[i])\n",
    "     \n",
    "\n",
    "plot_history(disc_loss=disc_loss, gen_loss=gen_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we fine-tune this network classes per classes, such that we could generate then specifically some classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gan import finetune_gan\n",
    "            \n",
    "for label in range(len(classes)):\n",
    "    finetune_gan(label, classes=classes, prefix=\"cifar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incorporating *a priori*\n",
    "Geometrical *a priori* are appealing for image classification tasks. For now, we only consider linear transformations $\\mathcal{T}$ of the inputs $x:\\mathbb{S}^2\\rightarrow\\mathbb{R}$ where $\\mathbb{S}$ is the support of an image, meaning that:\n",
    "\n",
    "$$\\forall u\\in\\mathbb{S}^2,\\mathcal{T}(\\lambda x+\\mu y)(u)=\\lambda \\mathcal{T}(x)(u)+\\mu \\mathcal{T}(y)(u)\\,.$$\n",
    "\n",
    "For instance if an image had an infinite support, a translation $\\mathcal{T}_a$ by $a$ would lead to:\n",
    "\n",
    "$$\\forall u, \\mathcal{T}_a(x)(u)=x(u-a)\\,.$$\n",
    "\n",
    "Otherwise, one has to handle several boundary effects.\n",
    "\n",
    "__Question 7:__ Explain the issues when dealing with translations, rotations, scaling effects, color changes on $32\\times32$ images. Propose several ideas to tackle them.\n",
    "\n",
    "> These operations on very small images might lead to several defects:\n",
    ">\n",
    "> - aliasing is likely to appear, but it could be partly compensated with an anti aliasing filter;\n",
    "> - even small affine transformation fill out significant part of the image; however, one could re-fill them with a padding pattern (e.g. applying a mirror effect on the missing pixels);\n",
    "> - scaling effects are in particular dangerous as it reduces the resolution; here, we could use sub-pixel methods.\n",
    ">\n",
    "> Finally, I decided to remove any affine transformation to focus only on constrained deformation (thin plate splines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 8:__ Propose a set of geometric transformation beyond translation, and incorporate them in your training pipeline. Train the model of the __Question 3__ and __Question 4__ with them and report the accuracies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from vgg import VGG\n",
    "from resnet import ResNet18\n",
    "from tps import random_tps\n",
    "\n",
    "input_size = 32\n",
    "transform = transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "        transforms.Lambda(random_tps),\n",
    "        transforms.RandomResizedCrop(input_size, scale=(0.95, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "batch_size = 10\n",
    "trainloader, validloader, testloader = get_loaders(batch_size=batch_size, train_transform=transform)\n",
    "\n",
    "# Initialize opt and net\n",
    "vgg = VGG('VGG11')\n",
    "vgg_opt = torch.optim.Adam(vgg.parameters())\n",
    "resnet = ResNet18()\n",
    "resnet_opt = torch.optim.Adam(resnet.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    vgg.cuda()\n",
    "    resnet.cuda()\n",
    "\n",
    "plot_examples(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for VGG\n",
    "n_epochs = 100\n",
    "\n",
    "vgg_train_loss = np.zeros(n_epochs, dtype=float)\n",
    "vgg_train_acc = np.zeros(n_epochs, dtype=float)\n",
    "vgg_valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        vgg_train_loss[i] = train_an_epoch(vgg, criterion, \n",
    "                 trainloader, vgg_opt, device, silent=True)\n",
    "        vgg_train_acc[i] = test(vgg, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        vgg_valid_acc[i] = test(vgg, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=vgg_train_loss[i], train_acc=vgg_train_acc[i], valid_acc=vgg_valid_acc[i])\n",
    "     \n",
    "\n",
    "plot_history(train_loss=vgg_train_loss, train_acc=vgg_train_acc, valid_acc=vgg_valid_acc)\n",
    "test(vgg, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training for Resnet\n",
    "rn_train_loss = np.zeros(n_epochs, dtype=float)\n",
    "rn_train_acc = np.zeros(n_epochs, dtype=float)\n",
    "rn_valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        rn_train_loss[i] = train_an_epoch(resnet, criterion, \n",
    "                 trainloader, resnet_opt, device, silent=True)\n",
    "        rn_train_acc[i] = test(resnet, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        rn_valid_acc[i] = test(resnet, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=rn_train_loss[i], train_acc=rn_train_acc[i], valid_acc=rn_valid_acc[i])\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_history(train_loss=rn_train_loss, train_acc=rn_train_acc, valid_acc=rn_valid_acc)\n",
    "test(resnet, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation has slightly improved our baseline, but it remains lower than with a pre-training or with Keshari et al. method.\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|VGG11 |  14 | 100.0% | 27.0% |\n",
    "|ResNet-augmented |  100 | 100.0% | 25.0% |\n",
    "|VGG11-augmented |  100 | 100.0% | 29.5% |\n",
    "|[Keshari-ResNet]| N/A | N/A | 36% | \n",
    "|[Keshari-ResNet-pretrained]| N/A | N/A | 44% | \n",
    "|**ResNet-pretrained**| 35 | 76% | 51% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wavelets\n",
    "\n",
    "__Question 9:__ Use a Scattering Transform as an input to a ResNet-like architecture. You can find a baseline here: https://arxiv.org/pdf/1703.08961.pdf.\n",
    "\n",
    "*Hint:* You can use the following package: https://www.kymat.io/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scattering import Scattering2dResNet, ScatteringCIFAR10\n",
    "import torch.optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from kymatio import Scattering2D\n",
    "import torch\n",
    "import argparse\n",
    "import kymatio.datasets as scattering_datasets\n",
    "import torch.nn as nn\n",
    "from utils import * \n",
    "\n",
    "# Parameters\n",
    "batch_size = 128\n",
    "n_epochs = 90 \n",
    "\n",
    "# Loading model and so on\n",
    "model = Scattering2dResNet(81*3, 2).to(device)\n",
    "scattering = Scattering2D(J=2, shape=(32, 32))\n",
    "train_transform = transforms.Compose(\n",
    "            [transforms.RandomResizedCrop(input_size),\n",
    "             transforms.RandomHorizontalFlip(),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "            ])\n",
    "augmented_transform = transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "        transforms.Lambda(random_tps),\n",
    "        transforms.RandomResizedCrop(input_size, scale=(0.95, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "# trainloader, validloader, testloader = get_loaders(\n",
    "#     batch_size=batch_size, train_transform=train_transform)\n",
    "trainloader, validloader, testloader = get_loaders(\n",
    "    batch_size=batch_size, train_transform=augmented_transform)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "use_cuda = torch.cuda.is_available()        \n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    scattering = scattering.cuda()\n",
    "    model.cuda()\n",
    "\n",
    "# Training\n",
    "train_loss = np.zeros(n_epochs, dtype=float)\n",
    "train_acc = np.zeros(n_epochs, dtype=float)\n",
    "valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        train_loss[i] = train_an_epoch(model, criterion, \n",
    "                 trainloader, optimizer, device, \n",
    "                 silent=True, callback=scattering)\n",
    "        train_acc[i] = test(model, trainloader, \n",
    "                 criterion, device, silent=True, callback=scattering)\n",
    "        valid_acc[i] = test(model, validloader, criterion, device, \n",
    "                            silent=True, callback=scattering)\n",
    "        t.set_postfix(train_loss=train_loss[i], train_acc=train_acc[i], valid_acc=valid_acc[i])\n",
    "     \n",
    "plot_history(train_loss=train_loss, train_acc=train_acc, valid_acc=valid_acc)\n",
    "test(model, testloader, criterion, device, callback=scattering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scattering has improved the baseline!\n",
    "Data augmentation has even allowed to do slightly better. Our level is then closed to the baseline of Keshari et al. without pre-training.\n",
    "\n",
    "Original paper presented a better baseline.\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|Scattering |  90 | 59.0% | 27.5% |\n",
    "|VGG11-augmented |  100 | 100.0% | 29.5% |\n",
    "|Scattering-augmented |  75 | 83.0% | 29.6% |\n",
    "|[Keshari-ResNet]| N/A | N/A | 36% | \n",
    "|[Oyallon-Scat + WRN 12-8]| N/A | N/A | 38.9% |\n",
    "|[Keshari-ResNet-pretrained]| N/A | N/A | 44% | \n",
    "|**ResNet-pretrained**| 35 | 76% | 51% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weak supervision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weakly supervised techniques permit to tackle the issue of labeled data. An introduction to those techniques can be found here: https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html.\n",
    "\n",
    "__(Open) Question 10:__ Pick a weakly supervised method that will potentially use $\\mathcal{X}\\cup\\mathcal{X}_{\\text{train}}$ to train a representation (a subset of $\\mathcal{X}$ is also fine). Evaluate it and report the accuracies. You should be careful in the choice of your method, in order to avoid heavy computational effort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> One solution consists in using the pre-trained GANs to generate classes. The GANs are trained to generate only one class. It will create errors, but it might be quite efficient to pre-train a classifier.\n",
    "> This is similar to a way to augment data since we trained GANs over the 100 samples from CIFAR10. However, I am slightly cheating (using more than 100 samples at total), because the GAN was pre-trained over STL10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tnrange\n",
    "from gan import DCGAN_Generator\n",
    "import os\n",
    "import torch\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "nf = 64\n",
    "nc = 3 \n",
    "nz = 100\n",
    "batch_size = 300\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "output = os.path.join(\"datasets\", \"generated\")\n",
    "\n",
    "\n",
    "\n",
    "for label in tnrange(len(classes)):\n",
    "    folder = os.path.join(output, classes[label])\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    netG = DCGAN_Generator(nf, nc, nz).to(device)\n",
    "    netG.load_state_dict(torch.load(f\"models/cifar-{classes[label]}/netG_epoch_{390}.pth\"))\n",
    "    noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "    fakes = netG(noise)\n",
    "    \n",
    "    for i, fake in enumerate(fakes):\n",
    "        fake = fake / 2 + 0.5     # unnormalize\n",
    "        filename = os.path.join(folder, f\"{i:03d}.jpg\")\n",
    "        save_image(fake, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I filtered manually images badly generated. Errors in generation came from mode collapses or remainding of the pre-trained (for example cars were sometimes produced in \"bird\" folder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_loaders, train_an_epoch, test, plot_history\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from vgg import VGG\n",
    "\n",
    "batch_size = 10\n",
    "n_epochs = 15\n",
    "_, validloader, testloader = get_loaders(batch_size=batch_size)\n",
    "transform = transforms.Compose(\n",
    "            [transforms.RandomHorizontalFlip(),\n",
    "             transforms.Resize(32),\n",
    "             transforms.ToTensor(),\n",
    "             transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "trainset = ImageFolder(\"datasets/generated\", transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, \n",
    "    batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Initialize opt and net\n",
    "model = VGG('VGG11')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "# Training\n",
    "train_loss = np.zeros(n_epochs, dtype=float)\n",
    "train_acc = np.zeros(n_epochs, dtype=float)\n",
    "valid_acc = np.zeros(n_epochs, dtype=float)\n",
    "\n",
    "with tnrange(n_epochs) as t:\n",
    "    for i in t:\n",
    "        train_loss[i] = train_an_epoch(model, criterion, \n",
    "                 trainloader, optimizer, device, silent=True)\n",
    "        train_acc[i] = test(model, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        valid_acc[i] = test(model, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=train_loss[i], train_acc=train_acc[i], valid_acc=valid_acc[i])\n",
    "     \n",
    "\n",
    "\n",
    "plot_history(train_loss=train_loss, train_acc=train_acc, valid_acc=valid_acc)\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results are not very strong but data were faked. Finally, we train the VGG over the real samples with the same data augmentation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from vgg import VGG\n",
    "from tps import random_tps\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.05, saturation=0.05, hue=0.05),\n",
    "        transforms.Lambda(random_tps),\n",
    "        transforms.RandomResizedCrop(30, scale=(0.95, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        \n",
    "    ])\n",
    "trainloader, _, _ = get_loaders(batch_size=batch_size, train_transform=transform)\n",
    "\n",
    "# Initialize opt and net\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training\n",
    "n_epochs2 = 150\n",
    "train_loss = np.pad(train_loss, (0, n_epochs2), mode=\"constant\")\n",
    "train_acc = np.pad(train_acc, (0, n_epochs2), mode=\"constant\")\n",
    "valid_acc = np.pad(valid_acc, (0, n_epochs2), mode=\"constant\")\n",
    "\n",
    "with tnrange(n_epochs, n_epochs2) as t:\n",
    "    for i in t:\n",
    "        train_loss[i] = train_an_epoch(model, criterion, \n",
    "                 trainloader, optimizer, device, silent=True)\n",
    "        train_acc[i] = test(model, trainloader, \n",
    "                 criterion, device, silent=True)\n",
    "        valid_acc[i] = test(model, validloader, criterion, device, silent=True)\n",
    "        t.set_postfix(train_loss=train_loss[i], train_acc=train_acc[i], valid_acc=valid_acc[i])\n",
    "     \n",
    "plot_history(train_loss=train_loss, train_acc=train_acc, valid_acc=valid_acc)\n",
    "test(model, testloader, criterion, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All in all, results are not satisfaying at all.\n",
    "That is why, I finally tried with: \n",
    "\n",
    "*Semi-Supervised Learning with Ladder Networks*, NeurIPS 201.Antti Rasmus, Harri Valpola, Mikko Honkala, Mathias Berglund, Tapani Raiko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ladder\n",
    "!conda activate ladder\n",
    "!python run.py train --encoder-layers convv:96:3:1:1-convf:96:3:1:1-convf:96:3:1:1-maxpool:2:2-convv:192:3:1:1-convf:192:3:1:1-convv:192:3:1:1-maxpool:2:2-convv:192:3:1:1-convv:192:1:1:1-convv:10:1:1:1-globalmeanpool:0 --decoder-spec 0-0-0-0-0-0-0-0-0-0-0-0-0 --dataset cifar10 --act leakyrelu --denoising-cost-x 0,0,0,0,0,0,0,0,0,0,0,0,0 --num-epochs 20 --lrate-decay 0.5 --seed 1 --whiten-zca 3072 --contrast-norm 55 --top-c False --labeled-samples 100 --unlabeled-samples 50000 -- cifar_4k_baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results were pretty good:\n",
    "\n",
    "| Model | Number of  epochs  | Train accuracy | Test accuracy |\n",
    "|------|------|------|------|\n",
    "|Scattering |  90 | 59.0% | 27.5% |\n",
    "|VGG11-augmented |  100 | 100.0% | 29.5% |\n",
    "|Scattering-augmented |  75 | 83.0% | 29.6% |\n",
    "|[Rasmus-Ladder] |  20 | 86.1 | 35.3% |\n",
    "|[Keshari-ResNet]| N/A | N/A | 36% | \n",
    "|[Oyallon-Scat + WRN 12-8]| N/A | N/A | 38.9% |\n",
    "|[Keshari-ResNet-pretrained]| N/A | N/A | 44% | \n",
    "|**ResNet-pretrained**| 35 | 76% | 51% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 11:__ Write a short report explaining the pros and the cons of each methods that you implemented. 25 of the grade of this project will correspond to this question, thus, it should be done carefully. In particular, please add a plot that will summarize all your numerical results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook presents several ways to deal with small datasets. Deep neural networks are known to be data-hungry. Indeed, with their astronishing number of parameters (e.g., ResNet-50 has  25.6 millions of parameters), it seems unlikely to train a neural network with 100 images of $32\\times32$ pixels, namely 10k samples at pixel scale.\n",
    "Nevertheless, the mini project shows that deep neural networks are appealing even for small datasets; neural networks just require a different setup.\n",
    "The considered dataset is a subset of 100 samples from CIFAR-10.  CIFAR-10 is a widely used in the literature, which allows us to compare with different baselines.\n",
    "\n",
    "At first, we compare VGG and ResNet, two general purpose architectures. Although ResNet is known to provide better results than VGG on large datasets (ResNet obtains a 3.6 top-5 error on ImageNet where VGG gets a 7.3 error rate), VGG11 outperformed Resnet-18. Results were though relatively low with less 30 accuracy for both of them. \n",
    "\n",
    "We then draw a strong baseline by using pre-trained weights on ImageNet. The test accuracy jumped to 51 for ResNet. However, this score is a little different from what we want: training a neural network with a few samples as possible.\n",
    "\n",
    "The next idea consisted in using augmenting the data. First, I augmented the data with affine transformation, but for an image of $32\\times32$, the distortion was too damaging. Increasing the image size did not really help. Therefore, I use a softer geometric transformation, called a thin plate spline. Mixing it with color variations allowed me to increase the baseline for VGG by a few points in the test accuracy. \n",
    "\n",
    "I thought also that I could achieve some data augmentations using GAN. This already happened in the literature [1] , but in practice, it is very difficult to do. My GAN was not trained well enough on the 100 samples, so I trained it STL-10, before fine-tuning it on each classes of CIFAR-10 (using only 100 samples). Generated images were manually filtered.\n",
    "\n",
    "Finally, I run two different methods from the literature: scattering networks [2] and ladder networks [3]. The latter one is using semi-supervised technics.\n",
    "\n",
    "The following figure summarizes the obtained results:\n",
    "\n",
    "![Final results](results/final.png)\n",
    "\n",
    "\n",
    "[1] - *GAN Augmentation: Augmenting Training Data using Generative Adversarial Networks*, Christopher Bowles, Liang Chen, Ricardo Guerrero, Paul Bentley, Roger Gunn, Alexander Hammers, David Alexander Dickie, Maria Valdés Hernández, Joanna Wardlaw, Daniel Rueckert\n",
    "\n",
    "[2] - *Scaling the Scattering Transform: Deep Hybrid Networks*, Edouard Oyallon, Eugene Belilovsky, Sergey Zagoruyko\n",
    "\n",
    "[3] - *Semi-Supervised Learning with Ladder Networks*, Antti Rasmus, Harri Valpola, Mikko Honkala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "models = {\n",
    "    \"Scattering\": [90, 0.59, 0.275], \n",
    "    \"VGG11-augmented\": [100, 1.0, .295], \n",
    "    \"Scattering-augmented\": [75, .83, 0.296], \n",
    "    \"[Rasmus-Ladder]\": [20, 0.86, 0.35], \n",
    "    \"[Keshari-ResNet]\": [\"N/A\", \"N/A\", 0.36], \n",
    "    \"[Oyallon-Scat + WRN 12-8]\": [\"N/A\", \"N/A\", 0.39], \n",
    "    \"[Keshari-ResNet-pretrained]\": [\"N/A\", \"N/A\", 0.44], \n",
    "    \"ResNet-pretrained\": [35, .76, 0.51]}\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "for i, (name, values) in enumerate(models.items()):\n",
    "    plt.scatter(i, values[-1], label=name)\n",
    "plt.legend()\n",
    "plt.title(\"Results obtained when training a classifier on a CIFAR-10 subset of 100 samples\")\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
