\section{Further work}
\label{sec:related}

The numerous research papers driven by the challenges SiSEC and MIREX
developed new ideas for separating musical sources with DNNs.

Several papers adapted technics from research in image recognition
into music source separation, such as convolution
layers \cite{chandna2017monoaural} or data augmentation~\cite{uhlich2017improving}.

Takahashi et al.~\cite{takahashi2018phasenet} refutes the use of the mixture phase for each source's
phase. Because the phase is difficult to predict, they assumed that the phase
can take discrete values, such that the problem becomes a classification one.

The best results so far were attained by Takahashi et al. in another paper~\cite{takahashi2018mmdenselstm}.
They are using a recurrent neural network, a bidirectional LSTM, combined to
dense layers, to predict the magnitude of each source given the magnitude of the
mixture signal.

Another interesting attempt to solve this challenge is proposed by Lluis et al.
\cite{lluis2018end}. The authors train an end-to-end neural network to predict each source
directly from the mixture waveform. The key ideas of their method consists in
using large dilatation combined with residual connections.
